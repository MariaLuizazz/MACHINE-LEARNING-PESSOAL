{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#machine-learning-project-template","title":"Machine Learning Project Template","text":"<p>Este reposit\u00f3rio fornece uma estrutura completa para desenvolver projetos de ci\u00eancia de dados e machine learning, com foco em reprodutibilidade, organiza\u00e7\u00e3o de c\u00f3digo, boas pr\u00e1ticas e documenta\u00e7\u00e3o.</p> <ul> <li>Compara\u00e7\u00e3o de Algoritmos de Machine Learning </li> </ul> <p>Este projeto tem como objetivo comparar o desempenho de diferentes algoritmos de Machine Learning aplicados a um mesmo problema de classifica\u00e7\u00e3o: a previs\u00e3o de c\u00e2ncer de mama a partir de dados cl\u00ednicos.</p> <p>Todos os modelos utilizam a mesma base de dados do Kaggle, garantindo que a compara\u00e7\u00e3o seja justa e que as diferen\u00e7as de resultado estejam relacionadas apenas ao comportamento de cada algoritmo, e n\u00e3o aos dados.</p>"},{"location":"#objetivo-do-projeto","title":"Objetivo do Projeto","text":"<p>O principal objetivo \u00e9:</p> <ul> <li>Avaliar como diferentes algoritmos se comportam no mesmo dataset.</li> <li>Comparar m\u00e9tricas de desempenho como accuracy, precision, recall, F1-score, etc.</li> <li>Entender os pontos fortes e fracos de cada abordagem</li> <li>Criar uma base s\u00f3lida de estudo sobre modelos de classifica\u00e7\u00e3o supervisionada</li> </ul>"},{"location":"#dataset-breast-cancer","title":"Dataset: Breast Cancer","text":""},{"location":"#1-contextualizacao-do-problema","title":"1. Contextualiza\u00e7\u00e3o do Problema","text":"<p>O c\u00e2ncer de mama \u00e9 uma das doen\u00e7as oncol\u00f3gicas mais comuns no mundo e representa um importante problema de sa\u00fade p\u00fablica, tanto em pa\u00edses desenvolvidos quanto em pa\u00edses em desenvolvimento. De acordo com organiza\u00e7\u00f5es internacionais de sa\u00fade, trata-se de uma das principais causas de mortalidade por c\u00e2ncer entre mulheres, embora tamb\u00e9m possa ocorrer, em menor frequ\u00eancia, em homens.</p> <p>A detec\u00e7\u00e3o precoce do c\u00e2ncer de mama \u00e9 um fator determinante para o aumento das chances de sucesso no tratamento e para a redu\u00e7\u00e3o da taxa de mortalidade. Nesse contexto, exames cl\u00ednicos, de imagem e an\u00e1lises laboratoriais produzem uma grande quantidade de dados que podem ser utilizados para auxiliar o processo de diagn\u00f3stico m\u00e9dico.</p> <p>Com o avan\u00e7o da Ci\u00eancia de Dados e do Machine Learning, tornou-se cada vez mais relevante o uso de modelos computacionais capazes de identificar padr\u00f5es em dados cl\u00ednicos e apoiar especialistas na tomada de decis\u00e3o. Embora esses modelos n\u00e3o substituam o diagn\u00f3stico m\u00e9dico, eles podem atuar como ferramentas de suporte, aumentando a efici\u00eancia, a consist\u00eancia e a confiabilidade das an\u00e1lises.</p>"},{"location":"#2-justificativa-da-escolha-do-dataset","title":"2. Justificativa da Escolha do Dataset","text":"<p>O Breast Cancer Dataset, disponibilizado publicamente na plataforma Kaggle, foi escolhido para este projeto por diversas raz\u00f5es:</p> <ul> <li>Trata-se de um dataset amplamente utilizado na literatura e em estudos educacionais, o que facilita a compara\u00e7\u00e3o de resultados e a valida\u00e7\u00e3o de abordagens</li> <li>Possui um problema de classifica\u00e7\u00e3o bem definido e de alta relev\u00e2ncia pr\u00e1tica: distinguir tumores benignos de tumores malignos</li> <li>Apresenta dados j\u00e1 estruturados e numericamente representados, permitindo foco no estudo dos algoritmos de Machine Learning e em sua capacidade de generaliza\u00e7\u00e3o</li> <li>\u00c9 adequado para experimentos controlados de compara\u00e7\u00e3o entre modelos, uma vez que possui boa qualidade de dados e dimensionalidade compat\u00edvel com diferentes t\u00e9cnicas de classifica\u00e7\u00e3o</li> </ul> <p>Al\u00e9m disso, o tema possui alto impacto social, o que torna o projeto n\u00e3o apenas tecnicamente interessante, mas tamb\u00e9m relevante do ponto de vista aplicado.</p>"},{"location":"#3-consideracoes-eticas-e-limitacoes","title":"3. Considera\u00e7\u00f5es \u00c9ticas e Limita\u00e7\u00f5es","text":"<p>\u00c9 importante ressaltar que este dataset \u00e9 utilizado exclusivamente para fins educacionais e experimentais. Os modelos desenvolvidos neste projeto:</p> <ul> <li>N\u00e3o substituem diagn\u00f3stico m\u00e9dico</li> <li>N\u00e3o devem ser utilizados em ambientes cl\u00ednicos reais</li> <li>Servem apenas como estudo de caso para avalia\u00e7\u00e3o de t\u00e9cnicas de Machine Learning</li> </ul> <p>O objetivo central \u00e9 compreender o comportamento dos algoritmos e o processo de modelagem, e n\u00e3o propor uma solu\u00e7\u00e3o cl\u00ednica definitiva.</p>"},{"location":"#algoritmos-testados","title":"Algoritmos Testados","text":"<p>Neste projeto, s\u00e3o testados diferentes tipos de modelos, como por exemplo:</p> <ul> <li>Regress\u00e3o Log\u00edstica</li> <li>KNN (K-Nearest Neighbors)</li> <li>\u00c1rvore de Decis\u00e3o</li> <li>Random Forest</li> <li>SVM</li> <li>(outros que venham a ser adicionados)</li> </ul> <p>Cada algoritmo \u00e9:</p> <ul> <li>Treinado com os mesmos dados</li> <li>Avaliado com as mesmas m\u00e9tricas</li> <li>Comparado de forma objetiva com os demais</li> </ul>"},{"location":"#metodologia","title":"Metodologia","text":"<p>O fluxo de trabalho do projeto segue as etapas:</p> <ol> <li>Entendimento do problema</li> <li>An\u00e1lise explorat\u00f3ria dos dados (EDA)</li> <li>Pr\u00e9-processamento e tratamento dos dados</li> <li>Treinamento dos modelos</li> <li>Avalia\u00e7\u00e3o e compara\u00e7\u00e3o dos resultados</li> <li>An\u00e1lise cr\u00edtica do desempenho de cada algoritmo</li> </ol>"},{"location":"#por-que-este-projeto-e-relevante","title":"Por que este projeto \u00e9 relevante?","text":"<p>Este tipo de compara\u00e7\u00e3o \u00e9 extremamente comum no mercado, pois raramente sabemos de antem\u00e3o qual algoritmo ser\u00e1 o melhor.</p> <p>O valor est\u00e1 justamente em:</p> <p>Testar, medir, comparar e decidir com base em evid\u00eancia.</p> <p>Este projeto demonstra n\u00e3o apenas o uso de modelos, mas m\u00e9todo cient\u00edfico aplicado \u00e0 ci\u00eancia de dados.</p>"},{"location":"KMEANS/main/","title":"KMEANS","text":""},{"location":"KMEANS/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<p>Descri\u00e7\u00e3o da base de dados e c\u00f3digo de explora\u00e7\u00e3o</p> <p>O c\u00e2ncer de mama \u00e9 o tipo de c\u00e2ncer mais comum entre mulheres em todo o mundo, respons\u00e1vel por aproximadamente 25% de todos os casos e afetando milh\u00f5es de pessoas todos os anos. Ele se desenvolve quando c\u00e9lulas da mama come\u00e7am a crescer de forma descontrolada, formando tumores que podem ser identificados por exames de imagem (raios-X) ou detectados como n\u00f3dulos.</p> <p>O principal desafio no diagn\u00f3stico \u00e9 diferenciar corretamente os tumores malignos (cancerosos) dos benignos (n\u00e3o cancerosos). O objetivo deste projeto \u00e9 desenvolver um modelo de classifica\u00e7\u00e3o supervisionada capaz de prever, com base em atributos num\u00e9ricos das c\u00e9lulas, se um tumor \u00e9 maligno ou benigno.</p> <p>Sobre o Dataset</p> <p>Total de registros: 569 amostras</p> <p>Vari\u00e1vel alvo: diagnosis (M = maligno, B = benigno)</p> <p>N\u00famero de vari\u00e1veis preditoras: 30 atributos num\u00e9ricos relacionados ao tamanho, textura, formato e concavidade das c\u00e9lulas</p> CodeResultado <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\nprint(df.sample(n=10, random_state=42).to_markdown(index=False))\n</code></pre> id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 87930 B 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 859575 M 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 8670 M 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 907915 B 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 921385 B 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 927241 M 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 9012000 M 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 853201 M 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 8611161 B 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 911673 B 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698 <p>Cada ponto azul/roxo/amarelo no gr\u00e1fico \u00e9 um paciente representado nessas duas dimens\u00f5es condensadas.</p> <p>Esses componentes carregam a maior parte da variabilidade dos dados originais (30 features)</p> <p>Voc\u00ea aplicou PCA para reduzir a dimensionalidade dos dados.</p> <p>O primeiro componente principal explica \u224844,3% da vari\u00e2ncia total dos dados.</p> <p>O segundo componente principal explica \u224818,97% da vari\u00e2ncia.</p> <p>Isso significa que, juntos, os dois componentes capturam \u224863,2% da informa\u00e7\u00e3o original do dataset.</p>"},{"location":"KMEANS/main/#relatorio-do-modelo-k-means-com-pca","title":"Relat\u00f3rio do Modelo: K-Means com PCA","text":""},{"location":"KMEANS/main/#1-descricao-do-modelo","title":"1. Descri\u00e7\u00e3o do Modelo","text":"<p>O modelo aplicado combina duas t\u00e9cnicas:</p> <ol> <li>PCA (An\u00e1lise de Componentes Principais): usada para reduzir a dimensionalidade dos dados originais, mantendo a maior parte da variabilidade.  </li> <li>K-Means: algoritmo de clustering que agrupa os dados em 3 clusters distintos com base na proximidade aos centr\u00f3ides.</li> </ol> <p>O objetivo do modelo \u00e9 identificar agrupamentos naturais nos dados de c\u00e2ncer de mama, considerando as caracter\u00edsticas das c\u00e9lulas.</p>"},{"location":"KMEANS/main/#2-variancia-explicada-pelos-componentes-principais","title":"2. Vari\u00e2ncia Explicada pelos Componentes Principais","text":"Componente Principal Vari\u00e2ncia Explicada Vari\u00e2ncia Acumulada PC1 0,44272 0,44272 PC2 0,189712 0,632432 <ul> <li>PC1 explica aproximadamente 44,3% da vari\u00e2ncia dos dados.  </li> <li>PC2 explica aproximadamente 18,97%.  </li> <li>Vari\u00e2ncia total explicada pelos 2 componentes: 63,24%.  </li> </ul> <p>Interpreta\u00e7\u00e3o: Mais da metade da informa\u00e7\u00e3o original dos dados \u00e9 preservada nesses dois componentes, permitindo uma visualiza\u00e7\u00e3o e an\u00e1lise de clusters eficaz.</p>"},{"location":"KMEANS/main/#3-centroides-finais-dos-clusters","title":"3. Centr\u00f2ides Finais dos Clusters","text":"<p>Os centr\u00f3ides identificados pelo K-Means no espa\u00e7o reduzido (PCA) s\u00e3o:</p> <p>[[ 2.67596132 3.31195566] \u2192 Cluster 1 [-2.3259273 -0.20749033] \u2192 Cluster 2 [ 4.90974577 -1.89255356]] \u2192 Cluster 3</p> <ul> <li>Cada centr\u00f3ide representa o \u201cponto m\u00e9dio\u201d de cada cluster.  </li> <li>Cada ponto do dataset \u00e9 atribu\u00eddo ao cluster cujo centr\u00f3ide est\u00e1 mais pr\u00f3ximo.</li> </ul>"},{"location":"KMEANS/main/#4-inercia-wcss","title":"4. In\u00e9rcia (WCSS)","text":"<ul> <li>In\u00e9rcia final: 3871,15  </li> <li>Representa a soma das dist\u00e2ncias quadr\u00e1ticas dos pontos aos seus centr\u00f3ides.  </li> <li>Quanto menor a in\u00e9rcia, mais compactos s\u00e3o os clusters.</li> </ul> <p>Interpreta\u00e7\u00e3o pr\u00e1tica: A dispers\u00e3o dos clusters \u00e9 moderada. Para otimizar o n\u00famero de clusters, pode-se usar o m\u00e9todo do cotovelo.</p>"},{"location":"KMEANS/main/#5-grafico-dos-clusters","title":"5. Gr\u00e1fico dos Clusters","text":"ResultCode 2026-01-20T18:12:00.521753 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/ <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport pandas as pd\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n# Features\nX = df.drop(columns=['diagnosis', 'id'])\n\n\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n\nkmeans = KMeans(n_clusters=3, init='k-means++', max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Adicionar clusters ao dataframe\ndf['Cluster'] = labels\n\nplt.figure(figsize=(10, 8))\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', s=50)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n            c='red', marker='*', s=200, label='Centr\u00f3ides')\nplt.title('Clusters ap\u00f3s redu\u00e7\u00e3o de dimensionalidade (PCA)')\nplt.xlabel('Componente Principal 1')\nplt.ylabel('Componente Principal 2')\nplt.legend()\nplt.show()\n\n\n\n\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"KMEANS/main/#6-conclusao","title":"6. Conclus\u00e3o","text":"<ul> <li>O modelo reduziu os dados para 2 dimens\u00f5es mantendo 63% da vari\u00e2ncia, facilitando visualiza\u00e7\u00e3o.  </li> <li>Foram identificados 3 clusters distintos, cada um representado por um centr\u00f3ide.  </li> <li> <p>O WCSS sugere que os clusters s\u00e3o relativamente coesos.</p> </li> <li> <p>Explorar mais componentes do PCA para capturar mais variabilidade.  </p> </li> <li>Testar diferentes n\u00fameros de clusters (K) usando o m\u00e9todo do cotovelo.  </li> <li>Investigar quais caracter\u00edsticas impactam mais a separa\u00e7\u00e3o dos clusters.</li> </ul>"},{"location":"KNN/main/","title":"KNN","text":""},{"location":"KNN/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<p>Descri\u00e7\u00e3o da base de dados e c\u00f3digo de explora\u00e7\u00e3o</p> <p>O c\u00e2ncer de mama \u00e9 o tipo de c\u00e2ncer mais comum entre mulheres em todo o mundo, respons\u00e1vel por aproximadamente 25% de todos os casos e afetando milh\u00f5es de pessoas todos os anos. Ele se desenvolve quando c\u00e9lulas da mama come\u00e7am a crescer de forma descontrolada, formando tumores que podem ser identificados por exames de imagem (raios-X) ou detectados como n\u00f3dulos.</p> <p>O principal desafio no diagn\u00f3stico \u00e9 diferenciar corretamente os tumores malignos (cancerosos) dos benignos (n\u00e3o cancerosos). O objetivo deste projeto \u00e9 desenvolver um modelo de classifica\u00e7\u00e3o supervisionada capaz de prever, com base em atributos num\u00e9ricos das c\u00e9lulas, se um tumor \u00e9 maligno ou benigno, e estabelecer um diagn\u00f3stico confi\u00e1vel.</p> <p>Sobre o Dataset</p> <p>Total de registros: 569 amostras</p> <p>Vari\u00e1vel alvo: diagnosis (M = maligno, B = benigno)</p> <p>N\u00famero de vari\u00e1veis preditoras: 30 atributos num\u00e9ricos relacionados ao tamanho, textura, formato e concavidade das c\u00e9lulas.</p> Resultado id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 87930 B 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 859575 M 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 8670 M 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 907915 B 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 921385 B 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 927241 M 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 9012000 M 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 853201 M 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 8611161 B 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 911673 B 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698"},{"location":"KNN/main/#pre-processamento","title":"Pr\u00e9 processamento","text":"<p>Explica\u00e7\u00e3o dos processos realizados no pr\u00e9-processamento</p> <p>Antes do treinamento do modelo, foi realizado um pr\u00e9-processamento para garantir a qualidade e consist\u00eancia dos dados:</p> <p>Remo\u00e7\u00e3o de colunas irrelevantes \u2013 A coluna id foi descartada, pois n\u00e3o contribui para o aprendizado do modelo.</p> <p>Tratamento de valores ausentes \u2013 Foram encontrados valores faltantes em algumas vari\u00e1veis (concavity_worst e concave points_worst). Esses valores foram preenchidos utilizando a mediana.</p> <p>Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas \u2013 A vari\u00e1vel alvo diagnosis foi transformada em valores num\u00e9ricos por meio de Label Encoding (M = 1, B = 0), permitindo sua utiliza\u00e7\u00e3o pelo algoritmo de aprendizado.</p> <p>Todos os processos de pr\u00e9-processamento feitos no algoritmo de \u00e1rvore de decis\u00e3o foram feitos tamb\u00e9m no algoritmo de KNN.</p> CodeResultado <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n\n#pr\u00e9 processamento\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nX = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\nprint(df.sample(n=10, random_state=42).to_markdown(index=False))\n</code></pre> diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 0 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 1 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 1 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 0 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 0 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 1 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 1 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 1 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 0 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 0 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698"},{"location":"KNN/main/#divisao-dos-dados-treinamento-do-modelo-e-avaliacao-do-modelo","title":"Divis\u00e3o dos dados, Treinamento do Modelo e Avalia\u00e7\u00e3o do Modelo.","text":"<p>O dataset foi dividido em conjuntos de treino e teste com uma propor\u00e7\u00e3o de 80% treino e 20% teste.</p> <p>O questionamento principal foi: Quais features s\u00e3o mais relevantes para o diagn\u00f3stico de c\u00e2ncer de mama de acordo com o que foi fornecido no meu dataset?</p> <p>Ao analisar o dataset, foi bom lembrar que trata-se da previs\u00e3o de um diagn\u00f3stico, \u00e9 preciso entender a base e o que eu quero prever. Em uma pesquisa r\u00e1pida para entender melhor, conclu\u00ed que: para a escolha das minhas features eu deveria ficar atenta \u00e0s minhas vari\u00e1veis mais relevantes.</p> <p>Se o n\u00f3dulo \u00e9 redondo, pequeno e com bordas suaves \u2192 mais prov\u00e1vel benigno. Se o n\u00f3dulo \u00e9 grande, irregular, com bordas cheias de reentr\u00e2ncias \u2192 mais prov\u00e1vel maligno. N\u00f3dulos malignos costumam ser maiores, com contornos irregulares e n\u00e3o lisos, enquanto benignos tendem a ser mais arredondados e bem delimitados.</p> <p>Portanto, as vari\u00e1veis mais importantes do meu dataset para o diagn\u00f3stico seriam aquelas que especificam tamanho, formato e textura do n\u00f3dulo. No caso, as vari\u00e1veis escolhidas foram: texture_mean e radius_mean.</p> <p>TESTE 1 </p> <p>Ao analiser o primeiro gr\u00e1fico, o modelo paresentou sinais de overfitting, realizando uma valida\u00e7\u00e3o cruzada e matriz de confus\u00e3o foi  poss\u00edvel constatar que de acordo com o modelo sem balancemanto e com k = 3 que: </p> <p>102: Pacientes saud\u00e1veis corretamente diagnosticados</p> <p>5: Pacientes saud\u00e1veis erroneamente diagnosticados com c\u00e2ncer (Falso Positivo)</p> <p>14: Pacientes com c\u00e2ncer erroneamente diagnosticados como saud\u00e1veis (Falso Negativo - GRAVE)</p> <p>50: Pacientes com c\u00e2ncer corretamente diagnosticados</p> <p>Com esses erros o gr\u00e1fico resultou da seguinte forma: </p> ResultCode <p>Accuracy: 0.89  2026-01-20T18:12:02.567836 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/   Valida\u00e7\u00e3o Cruzada: 0.873 \u00b1 0.037 Matriz de Confus\u00e3o: [[102   5]  [ 14  50]] </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n\nplt.figure(figsize=(12,10))\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#Pr\u00e9process\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#escolha de features\nX = df[['radius_mean', 'texture_mean']]\ny = df['diagnosis']\n\n#Separa\u00e7\u00e3o de treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n#Treianamento do KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n\n\n#Teste e valida\u00e7\u00e3o\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n\n# Mapeia os r\u00f3tulos: 0 -&gt; Benigno, 1 -&gt; Maligno\nlabels_map = {0: \"Benigno\", 1: \"Maligno\"}\ny_labels = y.map(labels_map)\n\n\n#Prepara\u00e7\u00e3o para o gr\u00e1fico da fronteira de decis\u00e3o(malha de visualiza\u00e7\u00e3o)\nh = 0.02\nx_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\ny_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n\n#Prevendo classe em cada ponto\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n#gr\u00e1fico final\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlGn_r, alpha=0.3)\nsns.scatterplot(x=X.iloc[:, 0], y=X.iloc[:, 1], hue=y_labels, style=y_labels, palette={'Benigno': 'green', 'Maligno': 'red'}, s=100) #motivooooooo do errroo\nplt.xlabel(\"radius_mean\")\nplt.ylabel(\"texture_mean\")\nplt.title(\"KNN Decision Boundary (k=3) -  Diagn\u00f3stico de C\u00e2ncer\")\nplt.legend(title=\"Diagn\u00f3stico\")  \n\n\n\n#Exibi\u00e7\u00e3o do gr\u00e1fico\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n\n\n# 1. Valida\u00e7\u00e3o Cruzada\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(knn, X, y, cv=5)\nprint(f\"Valida\u00e7\u00e3o Cruzada: {scores.mean():.3f} \u00b1 {scores.std():.3f}\")\n\n\n# 3. Matriz de Confus\u00e3o\nfrom sklearn.metrics import confusion_matrix\nprint(\"Matriz de Confus\u00e3o:\")\nprint(confusion_matrix(y_test, predictions))\n</code></pre> <p>TESTE 2 </p> <p>No teste 2 ocorreu aplica\u00e7\u00e3o da t\u00e9cnica smote  apenas nos dados de treino para balanceamento, sem vazmento de informa\u00e7\u00f5es para o teste. Realizando uma valida\u00e7\u00e3o cruzada e matriz de confus\u00e3o foi  poss\u00edvel constatar que de acordo com o modelo co balancemento e com k = 11 que: </p> <p>O modelo balanceado com K=11 \u00e9 MAIS SEGURO que a vers\u00e3o anterior, reduzindo os perigosos falsos negativos em 28,6%.</p> <p>101: Pacientes saud\u00e1veis corretamente diagnosticados</p> <p>6: Pacientes saud\u00e1veis erroneamente diagnosticados com c\u00e2ncer (Falso Positivo)</p> <p>10: Pacientes com c\u00e2ncer erroneamente diagnosticados como saud\u00e1veis (Falso Negativo - GRAVE)</p> <p>54: Pacientes com c\u00e2ncer corretamente diagnosticados</p> <ul> <li>Conclus\u00e3o: a quantidade de falsos negativos cairam, e de positivos aumentou.</li> </ul> ResultCode <p>Accuracy: 0.91  2026-01-20T18:12:05.302947 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/   Valida\u00e7\u00e3o Cruzada: 0.884 \u00b1 0.036 Matriz de Confus\u00e3o: [[101   6]  [ 10  54]] </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE  \n\n\nplt.figure(figsize=(12,10))\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#Pr\u00e9process\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#escolha de features\n# Em vez de usar apenas 2 features\nX = df[['radius_mean', 'texture_mean']]\ny = df['diagnosis']\n\n#Separa\u00e7\u00e3o de treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\n\n\n#Treianamento do KNN\nknn = KNeighborsClassifier(n_neighbors=11)\nknn.fit(X_train_balanced, y_train_balanced) \n\n\n#Teste e valida\u00e7\u00e3o\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n\n# Mapeia os r\u00f3tulos: 0 -&gt; Benigno, 1 -&gt; Maligno\nlabels_map = {0: \"Benigno\", 1: \"Maligno\"}\ny_labels = y.map(labels_map)\n\n\n#Prepara\u00e7\u00e3o para o gr\u00e1fico da fronteira de decis\u00e3o(malha de visualiza\u00e7\u00e3o)\nh = 0.02\nx_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\ny_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n\n#Prevendo classe em cada ponto\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n#gr\u00e1fico final\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlGn_r, alpha=0.3)\nsns.scatterplot(x=X.iloc[:, 0], y=X.iloc[:, 1], hue=y_labels, style=y_labels, palette={'Benigno': 'green', 'Maligno': 'red'}, s=100) #motivooooooo do errroo\nplt.xlabel(\"radius_mean\")\nplt.ylabel(\"texture_mean\")\nplt.title(\"KNN Decision Boundary (k=11) - Diagn\u00f3stico de C\u00e2ncer (Com Balanceamento SMOTE)\")\nplt.legend(title=\"Diagn\u00f3stico\")  \n\n\n\n#Exibi\u00e7\u00e3o do gr\u00e1fico\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n\n\n\n# 1. Valida\u00e7\u00e3o Cruzada\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(knn, X, y, cv=5)\nprint(f\"Valida\u00e7\u00e3o Cruzada: {scores.mean():.3f} \u00b1 {scores.std():.3f}\")\n\n\n\n# 3. Matriz de Confus\u00e3o\nfrom sklearn.metrics import confusion_matrix\nprint(\"Matriz de Confus\u00e3o:\")\nprint(confusion_matrix(y_test, predictions))\n</code></pre>"},{"location":"KNN/main/#relatorio-final","title":"Relatorio final","text":"<ul> <li> <p>O modelo KNN com k=3 memoriza os dados de treino e usa dist\u00e2ncia para fazer previs\u00f5es. Para cada novo tumor, ele encontra os 3 tumores mais similares no conjunto de treino e decide pela maioria, a mesma coisa ocorre com k = 11.</p> </li> <li> <p>Sobre a Avalia\u00e7\u00e3o: Ap\u00f3s a etapa de treino e teste, o processo entregou uma acur\u00e1cia de 86% que nos mostra que o modelo acerta 86 em cada 100 previs\u00f5es. </p> </li> <li> <p>Sobre a Visualiza\u00e7\u00e3o: A fronteira de decis\u00e3o mostra como o modelo separa tumores benignos de malignos. \u00c1reas coloridas mostram onde o modelo prev\u00ea cada classe. Observando o modelo e a acur\u00e1cia o modelo apresenta sinais de overfitting.</p> </li> </ul> <p>Conclus\u00f5es - O balanceamento com SMOTE foi crucial para melhorar a detec\u00e7\u00e3o de casos malignos - k=11 mostrou-se superior a k=3 para este problema m\u00e9dico - A troca especificidade-sensibilidade foi clinicamente vantajosa - O modelo balanceado \u00e9 mais seguro para aplica\u00e7\u00e3o cl\u00ednica</p>"},{"location":"METRICAS/main/","title":"METRICAS","text":""},{"location":"METRICAS/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<p>Descri\u00e7\u00e3o da base de dados e c\u00f3digo de explora\u00e7\u00e3o</p> <p>O c\u00e2ncer de mama \u00e9 o tipo de c\u00e2ncer mais comum entre mulheres em todo o mundo, respons\u00e1vel por aproximadamente 25% de todos os casos e afetando milh\u00f5es de pessoas todos os anos. Ele se desenvolve quando c\u00e9lulas da mama come\u00e7am a crescer de forma descontrolada, formando tumores que podem ser identificados por exames de imagem (raios-X) ou detectados como n\u00f3dulos.</p> <p>O principal desafio no diagn\u00f3stico \u00e9 diferenciar corretamente os tumores malignos (cancerosos) dos benignos (n\u00e3o cancerosos). O objetivo deste projeto \u00e9 desenvolver um modelo de classifica\u00e7\u00e3o supervisionada capaz de prever, com base em atributos num\u00e9ricos das c\u00e9lulas, se um tumor \u00e9 maligno ou benigno, e estabelecer um diagn\u00f3stico confi\u00e1vel.</p> <p>Sobre o Dataset</p> <p>Total de registros: 569 amostras</p> <p>Vari\u00e1vel alvo: diagnosis (M = maligno, B = benigno)</p> <p>N\u00famero de vari\u00e1veis preditoras: 30 atributos num\u00e9ricos relacionados ao tamanho, textura, formato e concavidade das c\u00e9lulas.</p> Resultado id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 87930 B 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 859575 M 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 8670 M 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 907915 B 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 921385 B 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 927241 M 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 9012000 M 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 853201 M 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 8611161 B 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 911673 B 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698 <ol> <li>Prepara\u00e7\u00e3o dos Dados</li> </ol> <p>Os dados foram pr\u00e9-processados para garantir melhor qualidade nas previs\u00f5es. As principais etapas inclu\u00edram:</p> <p>Normaliza\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas.</p> <p>Aplica\u00e7\u00e3o do SMOTE (Synthetic Minority Oversampling Technique) para balanceamento das classes.</p> <p>Utiliza\u00e7\u00e3o de PCA (Principal Component Analysis) para redu\u00e7\u00e3o de dimensionalidade, garantindo menor complexidade e melhor desempenho computacional.</p> <ol> <li>Treinamento dos Modelos</li> </ol> <p>KNN (K-Nearest Neighbors): Algoritmo supervisionado baseado na proximidade dos vizinhos mais pr\u00f3ximos.</p> <p>KMeans (K-Means Clustering): Algoritmo n\u00e3o supervisionado de agrupamento, adaptado para a tarefa de classifica\u00e7\u00e3o.</p>"},{"location":"METRICAS/main/#aplicacao-da-tecnicas","title":"Aplica\u00e7\u00e3o da T\u00e9cnicas","text":"<p>Este projeto tem como objetivo avaliar e comparar o desempenho de dois algoritmos de Machine Learning \u2013 KNN (K-Nearest Neighbors) e KMeans (K-Means Clustering) \u2013 aplicados a um problema de classifica\u00e7\u00e3o bin\u00e1ria. A an\u00e1lise foi conduzida com foco em m\u00e9tricas de desempenho e matrizes de confus\u00e3o, de forma a compreender vantagens e limita\u00e7\u00f5es de cada abordagem.</p> <p>Implementa\u00e7\u00e3o do KNN </p> ResultadoCode <p>Accuracy: 0.91  2026-01-20T18:12:08.118769 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/ </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE  \n\n\nplt.figure(figsize=(12,10))\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#Pr\u00e9process\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#escolha de features\n# Em vez de usar apenas 2 features\nX = df[['radius_mean', 'texture_mean']]\ny = df['diagnosis']\n\n#Separa\u00e7\u00e3o de treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\n\n\n#Treianamento do KNN\nknn = KNeighborsClassifier(n_neighbors=11)\nknn.fit(X_train_balanced, y_train_balanced) \n\n\n#Teste e valida\u00e7\u00e3o\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n\n# Mapeia os r\u00f3tulos: 0 -&gt; Benigno, 1 -&gt; Maligno\nlabels_map = {0: \"Benigno\", 1: \"Maligno\"}\ny_labels = y.map(labels_map)\n\n\n#Prepara\u00e7\u00e3o para o gr\u00e1fico da fronteira de decis\u00e3o(malha de visualiza\u00e7\u00e3o)\nh = 0.02\nx_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\ny_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n\n#Prevendo classe em cada ponto\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n#gr\u00e1fico final\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlGn_r, alpha=0.3)\nsns.scatterplot(x=X.iloc[:, 0], y=X.iloc[:, 1], hue=y_labels, style=y_labels, palette={'Benigno': 'green', 'Maligno': 'red'}, s=100) #motivooooooo do errroo\nplt.xlabel(\"radius_mean\")\nplt.ylabel(\"texture_mean\")\nplt.title(\"KNN Decision Boundary (k=11) - Diagn\u00f3stico de C\u00e2ncer (Com Balanceamento SMOTE)\")\nplt.legend(title=\"Diagn\u00f3stico\")  \n\n\n\n#Exibi\u00e7\u00e3o do gr\u00e1fico\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre> <p>Implementa\u00e7\u00e3o do KMEANS </p> ResultadoCode 2026-01-20T18:12:08.379773 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/ <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport pandas as pd\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n# Features\nX = df.drop(columns=['diagnosis', 'id'])\n\n\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n\nkmeans = KMeans(n_clusters=3, init='k-means++', max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Adicionar clusters ao dataframe\ndf['Cluster'] = labels\n\nplt.figure(figsize=(10, 8))\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', s=50)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n            c='red', marker='*', s=200, label='Centr\u00f3ides')\nplt.title('Clusters ap\u00f3s redu\u00e7\u00e3o de dimensionalidade (PCA)')\nplt.xlabel('Componente Principal 1')\nplt.ylabel('Componente Principal 2')\nplt.legend()\nplt.show()\n\n\n\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"METRICAS/main/#matrizes-de-confusao","title":"Matrizes de Confus\u00e3o","text":"Resultado"},{"location":"METRICAS/main/#exec-5--matriz-de-confusao-knn","title":"Matriz de Confus\u00e3o - KNN","text":"Previsto Benigno Previsto Maligno Real Benigno 99 8 Real Maligno 7 57"},{"location":"METRICAS/main/#exec-5--matriz-de-confusao-kmeans","title":"Matriz de Confus\u00e3o - KMeans","text":"Previsto Benigno Previsto Maligno Real Benigno 354 3 Real Maligno 53 159"},{"location":"METRICAS/main/#avaliacao-dos-modelos","title":"Avalia\u00e7\u00e3o dos Modelos","text":"ResultadoCode <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import mode\n\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n# Pr\u00e9-processamento\ndf = df.drop(columns=['id'])\nlabel_encoder = LabelEncoder()\ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n# Corrigir valores ausentes\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n# Features selecionadas\nX = df[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n        'smoothness_mean', 'compactness_mean', 'concavity_mean']]\ny = df['diagnosis']\n\n#knn\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_pca, y, test_size=0.3, random_state=42, stratify=y\n)\n\n# Balanceamento com SMOTE\nsmote = SMOTE(random_state=42)\nX_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n\n# Treinamento do KNN\nknn = KNeighborsClassifier(n_neighbors=11)\nknn.fit(X_train_bal, y_train_bal)\n\n# Predi\u00e7\u00e3o\ny_pred_knn = knn.predict(X_test)\ncm_knn = confusion_matrix(y_test, y_pred_knn)\n\n# M\u00e9tricas KNN\nacc_knn = accuracy_score(y_test, y_pred_knn)\nprec_knn = precision_score(y_test, y_pred_knn)\nrec_knn = recall_score(y_test, y_pred_knn)\nf1_knn = f1_score(y_test, y_pred_knn)\n\n\n# Modelo 2: KMeans\nscaler_full = StandardScaler()\nX_scaled_full = scaler_full.fit_transform(X)\n\npca_full = PCA(n_components=2)\nX_pca_full = pca_full.fit_transform(X_scaled_full)\n\nkmeans = KMeans(n_clusters=2, init='k-means++', max_iter=100, random_state=42, n_init=10)\nclusters = kmeans.fit_predict(X_pca_full)\n\n# Mapear clusters para classes reais\nmapping = {}\nfor cluster in np.unique(clusters):\n    mask = clusters == cluster\n    mapping[cluster] = mode(y[mask], keepdims=True).mode[0]\n\ny_pred_kmeans = [mapping[c] for c in clusters]\ncm_kmeans = confusion_matrix(y, y_pred_kmeans)\n\n# M\u00e9tricas KMeans\nacc_kmeans = accuracy_score(y, y_pred_kmeans)\nprec_kmeans = precision_score(y, y_pred_kmeans)\nrec_kmeans = recall_score(y, y_pred_kmeans)\nf1_kmeans = f1_score(y, y_pred_kmeans)\n\n\n# Impress\u00e3o em Markdown\ndef matriz_markdown(cm, labels, titulo):\n    md = f\"### {titulo}\\n\\n\"\n    md += f\"|                 | Previsto {labels[0]} | Previsto {labels[1]} |\\n\"\n    md += f\"|-----------------|------------------|------------------|\\n\"\n    md += f\"| **Real {labels[0]}** | {cm[0,0]}              | {cm[0,1]}               |\\n\"\n    md += f\"| **Real {labels[1]}** | {cm[1,0]}              | {cm[1,1]}               |\\n\"\n    return md\n\nprint(matriz_markdown(cm_knn, [\"Benigno\", \"Maligno\"], \"Matriz de Confus\u00e3o - KNN\"))\nprint(f\"- Acur\u00e1cia: {acc_knn:.3f}\\n- Precis\u00e3o: {prec_knn:.3f}\\n- Recall: {rec_knn:.3f}\\n- F1-score: {f1_knn:.3f}\\n\")\n\nprint(matriz_markdown(cm_kmeans, [\"Benigno\", \"Maligno\"], \"Matriz de Confus\u00e3o - KMeans\"))\nprint(f\"- Acur\u00e1cia: {acc_kmeans:.3f}\\n- Precis\u00e3o: {prec_kmeans:.3f}\\n- Recall: {rec_kmeans:.3f}\\n- F1-score: {f1_kmeans:.3f}\\n\")\n\n\n# Compara\u00e7\u00e3o lado a lado em Markdown\ncomparacao = f\"\"\"\n### Compara\u00e7\u00e3o de M\u00e9tricas\n\n| Modelo   | Acur\u00e1cia | Precis\u00e3o | Recall | F1-score |\n|----------|----------|----------|--------|----------|\n| **KNN**  | {acc_knn:.3f} | {prec_knn:.3f} | {rec_knn:.3f} | {f1_knn:.3f} |\n| **KMeans**| {acc_kmeans:.3f} | {prec_kmeans:.3f} | {rec_kmeans:.3f} | {f1_kmeans:.3f} |\n\"\"\"\nprint(comparacao)\n</code></pre>"},{"location":"METRICAS/main/#exec-6--matriz-de-confusao-knn","title":"Matriz de Confus\u00e3o - KNN","text":"Previsto Benigno Previsto Maligno Real Benigno 99 8 Real Maligno 7 57 <ul> <li>Acur\u00e1cia: 0.912</li> <li>Precis\u00e3o: 0.877</li> <li>Recall: 0.891</li> <li>F1-score: 0.884</li> </ul>"},{"location":"METRICAS/main/#exec-6--matriz-de-confusao-kmeans","title":"Matriz de Confus\u00e3o - KMeans","text":"Previsto Benigno Previsto Maligno Real Benigno 354 3 Real Maligno 53 159 <ul> <li>Acur\u00e1cia: 0.902</li> <li>Precis\u00e3o: 0.981</li> <li>Recall: 0.750</li> <li>F1-score: 0.850</li> </ul>"},{"location":"METRICAS/main/#exec-6--comparacao-de-metricas","title":"Compara\u00e7\u00e3o de M\u00e9tricas","text":"Modelo Acur\u00e1cia Precis\u00e3o Recall F1-score KNN 0.912 0.877 0.891 0.884 KMeans 0.902 0.981 0.750 0.850"},{"location":"METRICAS/main/#comparacao-dos-resultados","title":"Compara\u00e7\u00e3o dos Resultados","text":"<p>A avalia\u00e7\u00e3o dos dois modelos (KNN e KMeans) permitiu observar diferen\u00e7as importantes em termos de desempenho, destacando pontos fortes e limita\u00e7\u00f5es de cada abordagem.</p> <p>O modelo KNN apresentou uma acur\u00e1cia de 91,2%, com m\u00e9tricas balanceadas entre precis\u00e3o (0,877), recall (0,891) e F1-score (0,884). Isso indica que o algoritmo teve um bom equil\u00edbrio entre identificar corretamente os casos benignos e malignos, sendo mais consistente no tratamento das duas classes. No entanto, a precis\u00e3o foi ligeiramente inferior, o que significa que, entre os casos previstos como malignos, houve uma propor\u00e7\u00e3o maior de falsos positivos em compara\u00e7\u00e3o ao KMeans.</p> <p>J\u00e1 o modelo KMeans, por se tratar de um algoritmo de aprendizado n\u00e3o supervisionado, surpreendeu ao alcan\u00e7ar uma acur\u00e1cia de 90,2%, pr\u00f3xima \u00e0 do KNN. Seu destaque foi a alta precis\u00e3o (0,981), ou seja, quase todas as amostras classificadas como malignas realmente pertenciam a essa classe. Por\u00e9m, essa alta precis\u00e3o veio acompanhada de uma queda no recall (0,750), mostrando que o KMeans deixou de identificar corretamente uma parcela consider\u00e1vel dos casos malignos, classificando-os como benignos. Isso \u00e9 cr\u00edtico em contextos sens\u00edveis, como o diagn\u00f3stico m\u00e9dico, em que falsos negativos podem trazer riscos significativos.</p> <ul> <li>De forma geral, pode-se afirmar que:</li> </ul> <p>O KNN \u00e9 mais equilibrado e confi\u00e1vel para cen\u00e1rios em que tanto falsos positivos quanto falsos negativos precisam ser controlados.</p> <p>O KMeans \u00e9 vantajoso em termos de precis\u00e3o, mas pode n\u00e3o ser o mais indicado em situa\u00e7\u00f5es em que a detec\u00e7\u00e3o completa dos casos positivos (alto recall) \u00e9 essencial.</p> <p>Portanto, a escolha entre os dois modelos depender\u00e1 diretamente do contexto de aplica\u00e7\u00e3o: se o objetivo for minimizar falsos negativos, o KNN se mostra mais adequado; se o objetivo for garantir maior seguran\u00e7a nas classifica\u00e7\u00f5es positivas, o KMeans pode ser preferido.</p>"},{"location":"RANDOMFOREST/main/","title":"RANDOM FOREST","text":""},{"location":"RANDOMFOREST/main/#modelo-de-classificacao-com-random-forest-breast-cancer-dataset","title":"Modelo de Classifica\u00e7\u00e3o com Random Forest \u2014 Breast Cancer Dataset","text":"Random forestCode <p>\u2705 Accuracy: 0.9708  2026-01-20T18:12:09.117567 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/ </p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom io import StringIO\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n# Remover coluna irrelevante\ndf = df.drop(columns=['id'])\n\n# Convers\u00e3o de letra para n\u00famero (diagnosis: M=1, B=0)\nlabel_encoder = LabelEncoder()\ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n# Imputa\u00e7\u00e3o com mediana para valores nulos\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n# Separa\u00e7\u00e3o entre vari\u00e1veis independentes e alvo\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n# Divis\u00e3o treino/teste\nx_train, x_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.3, random_state=42, stratify=y\n)\n\n\n# Cria\u00e7\u00e3o e treino do modelo Random Forest\nrf = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=5,\n    max_features='sqrt',\n    random_state=42\n)\nrf.fit(x_train, y_train)\n\n# Avalia\u00e7\u00e3o\npredictions = rf.predict(x_test)\nprint(f\"\u2705 Accuracy: {accuracy_score(y_test, predictions):.4f}\")\n\n# Import\u00e2ncia das vari\u00e1veis\nimportances = pd.DataFrame({\n    'Feature': x.columns,\n    'Importance': rf.feature_importances_\n}).sort_values(by='Importance', ascending=False)\n#print(\"\\n\ud83d\udcca Import\u00e2ncia das Features:\")\n#print(importances.head(10))\n\n# Plot de uma \u00e1rvore individual\nfn = list(x.columns)             # nomes das features\ncn = ['Benigno', 'Maligno']      # classes do diagn\u00f3stico\n\nfig, ax = plt.subplots(figsize=(20,10), dpi=150)\ntree.plot_tree(\n    rf.estimators_[0],\n    feature_names=fn,\n    class_names=cn,\n    filled=True,\n    rounded=True,\n    fontsize=8,\n    ax=ax\n)\n\n\nplt.title(\"\ud83c\udf32 \u00c1rvore Individual da Random Forest\")\nplt.show()\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"RANDOMFOREST/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>A base utilizada corresponde ao Breast Cancer Dataset, amplamente utilizado em estudos de Machine Learning para diagn\u00f3stico de c\u00e2ncer de mama. Cada linha representa uma amostra de tecido mam\u00e1rio, e cada coluna descreve caracter\u00edsticas morfol\u00f3gicas das c\u00e9lulas, como raio, textura, per\u00edmetro, \u00e1rea, concavidade e simetria. O objetivo \u00e9 prever se o diagn\u00f3stico \u00e9 benigno ou maligno.</p> <p>\ud83d\udd0d Natureza dos dados</p> <p>Tipo: dados tabulares Total de amostras: 569 registros Vari\u00e1vel alvo (diagnosis): Maligno (1) Benigno (0)</p> <p>Total de atributos: 30 vari\u00e1veis num\u00e9ricas cont\u00ednuas</p> <p>An\u00e1lise descritiva</p> <p>As vari\u00e1veis num\u00e9ricas apresentaram m\u00e9dias e desvios-padr\u00e3o variados, refletindo diferentes escalas de medi\u00e7\u00e3o. Por exemplo:</p> <p>radius_mean, area_mean e perimeter_mean possuem valores mais altos e correla\u00e7\u00e3o entre si;</p> <ul> <li>Vari\u00e1veis como concave points_mean e concavity_mean est\u00e3o fortemente associadas \u00e0 probabilidade de malignidade.</li> </ul>"},{"location":"RANDOMFOREST/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>O pr\u00e9-processamento envolveu limpeza, codifica\u00e7\u00e3o e tratamento de valores ausentes.</p> Code <pre><code>df = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\ndf = df.drop(columns=['id'])\n\n# Codifica\u00e7\u00e3o da vari\u00e1vel alvo\nlabel_encoder = LabelEncoder()\ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n# Imputa\u00e7\u00e3o de valores ausentes com a mediana\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n</code></pre> <p>A coluna id foi removida por n\u00e3o conter informa\u00e7\u00e3o relevante para o modelo.</p> <p>A vari\u00e1vel alvo diagnosis foi codificada com LabelEncoder, onde:</p> <p>M \u2192 1 (Maligno)</p> <p>B \u2192 0 (Benigno)</p> <p>As vari\u00e1veis com valores ausentes (concavity_mean e concave points_mean) foram imputadas com a mediana de cada respectiva coluna, garantindo consist\u00eancia sem distorcer a distribui\u00e7\u00e3o.</p> <p>Todas as features num\u00e9ricas foram mantidas em sua escala original, visto que a Random Forest n\u00e3o \u00e9 sens\u00edvel a normaliza\u00e7\u00e3o ou padroniza\u00e7\u00e3o.</p> <p>Resultado: base limpa, num\u00e9rica e pronta para o treino do modelo.</p>"},{"location":"RANDOMFOREST/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>O dataset foi dividido em:</p> <ul> <li>70% para treino</li> <li>30% para teste</li> </ul> Code <pre><code>x = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\nx_train, x_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.3, random_state=42, stratify=y\n)\n</code></pre> <p>A divis\u00e3o utilizou o par\u00e2metro stratify=y, garantindo que a propor\u00e7\u00e3o de diagn\u00f3sticos malignos e benignos fosse preservada em ambas as amostras. O par\u00e2metro random_state=42 assegurou a reprodutibilidade dos resultados.</p>"},{"location":"RANDOMFOREST/main/#treinamento-do-modelo","title":"Treinamento do  modelo","text":"<ul> <li>O modelo implementado foi o Random Forest Classifier, um ensemble de m\u00faltiplas \u00e1rvores de decis\u00e3o. A configura\u00e7\u00e3o utilizada foi a seguinte:</li> </ul> Code <pre><code>rf = RandomForestClassifier(\n    n_estimators=100,     # n\u00famero de \u00e1rvores\n    max_depth=5,          # profundidade m\u00e1xima\n    max_features='sqrt',  # n\u00famero de vari\u00e1veis avaliadas por split\n    random_state=42\n)\nrf.fit(x_train, y_train)\n</code></pre> <p>Essas configura\u00e7\u00f5es equilibram precis\u00e3o e interpretabilidade, evitando sobreajuste (overfitting) e mantendo uma boa capacidade de generaliza\u00e7\u00e3o.</p> <p>Durante o treinamento, cada \u00e1rvore foi constru\u00edda a partir de um subconjunto aleat\u00f3rio de dados e vari\u00e1veis, caracter\u00edstica que torna o modelo robusto e est\u00e1vel frente a ru\u00eddos.</p>"},{"location":"RANDOMFOREST/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"Random forest CONJUNTORandom forest INDIVIDUALCode <p>\u2705 Accuracy: 0.9708  2026-01-20T18:12:10.520009 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/ </p> <p>\u2705 Accuracy: 0.9708  2026-01-20T18:12:12.032538 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/ </p> <pre><code>predictions = rf.predict(x_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy: {accuracy:.4f}\")\n</code></pre> <p>O modelo atingiu 97,08% de acur\u00e1cia na base de teste, indicando excelente desempenho na classifica\u00e7\u00e3o entre tumores benignos e malignos.</p> <p> \ud83d\udcca Import\u00e2ncia das Vari\u00e1veis</p> <p>A an\u00e1lise da import\u00e2ncia das vari\u00e1veis mostrou que o modelo se baseia fortemente em caracter\u00edsticas geom\u00e9tricas e de textura das c\u00e9lulas. As 10 vari\u00e1veis mais relevantes foram:</p> Posi\u00e7\u00e3o Vari\u00e1vel Import\u00e2ncia 1 <code>area_worst</code> 0.171 2 <code>concave points_mean</code> 0.108 3 <code>concave points_worst</code> 0.103 4 <code>radius_worst</code> 0.084 5 <code>peripheral_worst</code> 0.082 6 <code>peripheral_mean</code> 0.076 7 <code>area_mean</code> 0.060 8 <code>concavity_mean</code> 0.057 9 <code>radius_mean</code> 0.047 10 <code>concavity_worst</code> 0.029 <ul> <li>As vari\u00e1veis relacionadas a \u00e1rea e concavidade s\u00e3o determinantes para o diagn\u00f3stico. Tumores malignos apresentam contornos mais irregulares e \u00e1reas maiores \u2014 o que justifica o peso elevado dessas vari\u00e1veis.</li> </ul>"},{"location":"RANDOMFOREST/main/#relatorio-final-e-consideracoes","title":"Relat\u00f3rio Final e Considera\u00e7\u00f5es","text":"<p>Conclus\u00f5es</p> <p>O modelo de Random Forest apresentou excelente desempenho, com acur\u00e1cia de 97%, interpretabilidade satisfat\u00f3ria e estabilidade nos resultados. A import\u00e2ncia das vari\u00e1veis refor\u00e7a a coer\u00eancia cl\u00ednica dos dados \u2014 caracter\u00edsticas morfol\u00f3gicas das c\u00e9lulas s\u00e3o realmente indicativas da natureza do tumor.</p>"},{"location":"decision-tree/main/","title":"\u00c1RVORE DE DECIS\u00c3O","text":""},{"location":"decision-tree/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<p>Descri\u00e7\u00e3o da base de dados e c\u00f3digo de explora\u00e7\u00e3o</p> <p>O c\u00e2ncer de mama \u00e9 o tipo de c\u00e2ncer mais comum entre mulheres em todo o mundo, respons\u00e1vel por aproximadamente 25% de todos os casos e afetando milh\u00f5es de pessoas todos os anos. Ele se desenvolve quando c\u00e9lulas da mama come\u00e7am a crescer de forma descontrolada, formando tumores que podem ser identificados por exames de imagem (raios-X) ou detectados como n\u00f3dulos.</p> <p>O principal desafio no diagn\u00f3stico \u00e9 diferenciar corretamente os tumores malignos (cancerosos) dos benignos (n\u00e3o cancerosos). O objetivo deste projeto \u00e9 desenvolver um modelo de classifica\u00e7\u00e3o supervisionada capaz de prever, com base em atributos num\u00e9ricos das c\u00e9lulas, se um tumor \u00e9 maligno ou benigno.</p> <p>Sobre o Dataset</p> <p>Total de registros: 569 amostras</p> <p>Vari\u00e1vel alvo: diagnosis (M = maligno, B = benigno)</p> <p>N\u00famero de vari\u00e1veis preditoras: 30 atributos num\u00e9ricos relacionados ao tamanho, textura, formato e concavidade das c\u00e9lulas</p> CodeResultado <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\nprint(df.sample(n=10, random_state=42).to_markdown(index=False))\n</code></pre> id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 87930 B 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 859575 M 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 8670 M 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 907915 B 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 921385 B 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 927241 M 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 9012000 M 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 853201 M 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 8611161 B 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 911673 B 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698"},{"location":"decision-tree/main/#pre-processamento","title":"Pr\u00e9-Processamento","text":"<p>Explica\u00e7\u00e3o dos processos realizados no pr\u00e9-processamento</p> <p>Antes do treinamento do modelo, foi realizado um pr\u00e9-processamento para garantir a qualidade e consist\u00eancia dos dados:</p> <p>Remo\u00e7\u00e3o de colunas irrelevantes \u2013 A coluna id foi descartada, pois n\u00e3o contribui para o aprendizado do modelo.</p> <p>Tratamento de valores ausentes \u2013 Foram encontrados valores faltantes em algumas vari\u00e1veis (concavity_worst e concave points_worst). Esses valores foram preenchidos utilizando a mediana, por ser uma t\u00e9cnica robusta contra outliers.</p> <p>Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas \u2013 A vari\u00e1vel alvo diagnosis foi transformada em valores num\u00e9ricos por meio de Label Encoding (M = 1, B = 0), permitindo sua utiliza\u00e7\u00e3o pelo algoritmo de aprendizado.</p> CodeResultado <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n\n#pr\u00e9 processamento\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\nprint(df.to_markdown(index=False))\n</code></pre> diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 0 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 1 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 1 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 0 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 0 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 1 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 1 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 1 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 0 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 0 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698"},{"location":"decision-tree/main/#divisao-de-dados","title":"Divis\u00e3o de Dados","text":"<p>Separa\u00e7\u00e3o em treino e teste</p> <p>O dataset foi dividido em conjuntos de treino e teste para permitir a avalia\u00e7\u00e3o do modelo em dados n\u00e3o vistos durante o treinamento. Foram utilizadas duas propor\u00e7\u00f5es distintas:</p> <p>Etapa I: 80% treino, 20% teste</p> <p>Etapa II: 70% treino, 30% teste</p> <p>Essa varia\u00e7\u00e3o foi realizada para observar como a quantidade de dados de treino impacta o desempenho do modelo.</p> Code <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n\n#pr\u00e9 processamento\n\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#divis\u00e3o de treinamento e teste \nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\nprint(df.to_markdown(index=False))\n</code></pre>"},{"location":"decision-tree/main/#treinamento-do-modelo","title":"Treinamento do modelo","text":"<p>Etapas do treinamento</p> <p>Na etapa de treinamento, foi utilizado o algoritmo de \u00c1rvore de Decis\u00e3o, por ser um m\u00e9todo simples, interpret\u00e1vel e bastante utilizado em problemas de classifica\u00e7\u00e3o inicial.</p> <p>ETAPA I:</p> <p>Divis\u00e3o: 80% treino, 20% teste</p> <p>Resultado: 93% de acur\u00e1cia</p> <p>ETAPA II:</p> <p>Divis\u00e3o: 70% treino, 30% teste</p> <p>Resultado: 90% de acur\u00e1cia</p> <p>Os resultados mostram que pequenas varia\u00e7\u00f5es na divis\u00e3o dos dados afetam a acur\u00e1cia final, embora o desempenho geral do modelo tenha se mantido satisfat\u00f3rio.</p> Code <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#pr\u00e9 processamento\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#divis\u00e3o de treinamento e teste \nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\nprint(df.sample(n=10, random_state=42).to_markdown(index=False))\n</code></pre>"},{"location":"decision-tree/main/#avaliacao-do-modelo-final","title":"Avalia\u00e7\u00e3o do Modelo Final","text":"<p>Ap\u00f3s os testes iniciais, foi feita a avalia\u00e7\u00e3o final do modelo. O foco desta etapa foi verificar o comportamento da \u00e1rvore de decis\u00e3o em termos de acur\u00e1cia e complexidade. A \u00e1rvore gerada inicialmente se apresentou pequena, sugerindo que o modelo poderia estar simplificando demais os padr\u00f5es dos dados (underfitting). Ap\u00f3s ajustes na propor\u00e7\u00e3o de dados de treino, a \u00e1rvore tornou-se mais consistente, refletindo melhor as rela\u00e7\u00f5es entre as vari\u00e1veis. O modelo alcan\u00e7ou 90% de acur\u00e1cia no conjunto de teste, isso significa que, a cada 100 diagn\u00f3sticos, 90 foram corretos.</p> <p>Embora existam modelos que possam alcan\u00e7ar valores um pouco maiores (como 95%+), a escolha dos 90% foi intencional:</p> <p>Por que 90% foi considerado adequado?</p> <ul> <li>Balanceamento entre desempenho e generaliza\u00e7\u00e3o</li> <li>Acima de 90%, o modelo come\u00e7ava a apresentar sinais de overfitting.</li> </ul> <p>Import\u00e2ncia cl\u00ednica</p> <ul> <li>No contexto de c\u00e2ncer de mama, evitar falsos negativos (n\u00e3o detectar um tumor maligno) \u00e9 prioridade.</li> </ul> <p>Conclus\u00e3o da Avalia\u00e7\u00e3o</p> <p>O modelo final com 90% de acur\u00e1cia foi escolhido por representar o melhor equil\u00edbrio entre desempenho, generaliza\u00e7\u00e3o e relev\u00e2ncia pr\u00e1tica para o contexto m\u00e9dico.</p> <p>Breast Cancer Dataset</p> decision treecode <p>Accuracy: 0.90  2026-01-20T18:12:12.867638 image/svg+xml Matplotlib v3.10.8, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#pr\u00e9 processamento\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n\n#divis\u00e3o de treinamento e teste \nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(x_train, y_train)\n\n# Plotar \u00e1rvore\nplt.figure(figsize=(12,10))\n\n# Avalia\u00e7\u00e3o o modelo, medindo a acuracia\naccuracy = classifier.score(x_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\ntree.plot_tree(classifier)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"decision-tree/main/#relatorio-final","title":"Relat\u00f3rio Final","text":"<p>Resumo do Projeto</p> <p>Este projeto teve como objetivo aplicar t\u00e9cnicas de Machine Learning para criar um modelo capaz de prever se um tumor de mama \u00e9 benigno ou maligno, utilizando o dataset Breast Cancer (Diagnostic).</p> <ul> <li>As etapas seguidas foram:</li> </ul> <p>Explora\u00e7\u00e3o de dados - Pr\u00e9-processamento - Divis\u00e3o de dados \u2013 separa\u00e7\u00e3o em treino e teste - Treinamento do modelo - Avalia\u00e7\u00e3o do modelo \u2013 an\u00e1lise do desempenho final com base na acur\u00e1cia e na estrutura da \u00e1rvore.</p> <p>Resultados Obtidos</p> <ul> <li>Acur\u00e1cia variando entre 90% e 93%, dependendo da propor\u00e7\u00e3o de treino/teste utilizada.</li> </ul> <p>Conclus\u00e3o</p> <p>Mesmo com limita\u00e7\u00f5es, o projeto cumpriu seu objetivo: desenvolver um modelo de classifica\u00e7\u00e3o supervisionada e aplicar todo o fluxo de pr\u00e9-processamento, treino e avalia\u00e7\u00e3o, consolidando o  meu aprendizado sobre o processo de Machine Learning.</p>"},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"svm/main/","title":"SVM","text":""},{"location":"svm/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos dados","text":"<p>Descri\u00e7\u00e3o da base de dados e c\u00f3digo de explora\u00e7\u00e3o</p> <p>O c\u00e2ncer de mama \u00e9 o tipo de c\u00e2ncer mais comum entre mulheres em todo o mundo, respons\u00e1vel por aproximadamente 25% de todos os casos e afetando milh\u00f5es de pessoas todos os anos. Ele se desenvolve quando c\u00e9lulas da mama come\u00e7am a crescer de forma descontrolada, formando tumores que podem ser identificados por exames de imagem (raios-X) ou detectados como n\u00f3dulos.</p> <p>O principal desafio no diagn\u00f3stico \u00e9 diferenciar corretamente os tumores malignos (cancerosos) dos benignos (n\u00e3o cancerosos). O objetivo deste projeto \u00e9 desenvolver um modelo de classifica\u00e7\u00e3o supervisionada capaz de prever, com base em atributos num\u00e9ricos das c\u00e9lulas, se um tumor \u00e9 maligno ou benigno.</p> <p>Sobre o Dataset</p> <p>Total de registros: 569 amostras</p> <p>Vari\u00e1vel alvo: diagnosis (M = maligno, B = benigno)</p> <p>N\u00famero de vari\u00e1veis preditoras: 30 atributos num\u00e9ricos relacionados ao tamanho, textura, formato e concavidade das c\u00e9lulas.</p> Resultado id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 87930 B 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 859575 M 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 8670 M 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 907915 B 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 921385 B 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 927241 M 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 9012000 M 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 853201 M 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 8611161 B 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 911673 B 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698"},{"location":"svm/main/#pre-processamento","title":"Pr\u00e9 - processamento","text":"<p>Antes do treinamento do modelo, foi realizado um pr\u00e9-processamento para garantir a qualidade e consist\u00eancia dos dados:</p> <p>Remo\u00e7\u00e3o de colunas irrelevantes \u2013 A coluna id foi descartada, pois n\u00e3o contribui para o aprendizado do modelo.</p> <p>Tratamento de valores ausentes \u2013 Foram encontrados valores faltantes em algumas vari\u00e1veis (concavity_worst e concave points_worst). Esses valores foram preenchidos utilizando a mediana, por ser uma t\u00e9cnica robusta contra outliers.</p> <p>Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas \u2013 A vari\u00e1vel alvo diagnosis foi transformada em valores num\u00e9ricos por meio de Label Encoding (M = 1, B = 0), permitindo sua utiliza\u00e7\u00e3o pelo algoritmo de aprendizado.</p> Code <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n\n#pr\u00e9 processamento\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\nprint(df.to_markdown(index=False))\n</code></pre>"},{"location":"svm/main/#divisao-de-dados-e-treinamneto-do-modelosvm-pca","title":"Divis\u00e3o de Dados e Treinamneto do Modelo(SVM + PCA)","text":"<p>O c\u00f3digo separa o conjunto de dados em dois grupos: um para treinar o modelo (x_train, y_train) e outro para avaliar seu desempenho (x_test, y_test). A divis\u00e3o usa 70% dos dados para treino e 30% para teste.</p> <p>A op\u00e7\u00e3o stratify=y garante que a propor\u00e7\u00e3o entre as classes (benigno/maligno) seja mantida igual nos dois conjutos. Isso evita que o modelo treine com mais exemplos de uma classe do que outra.</p> <p>O par\u00e2metro random_state=42 apenas fixa a semente aleat\u00f3ria, garantindo que a mesma divis\u00e3o sempre seja reproduzida.</p> <pre><code># Divis\u00e3o treino/teste\nx_train, x_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.3, random_state=42, stratify=y)\n</code></pre>"},{"location":"svm/main/#aplicacao-do-pca","title":"Aplica\u00e7\u00e3o do PCA :","text":"<p>O PCA (Principal Component Analysis) reduz a dimensionalidade dos dados de entrada para 2 componentes principais.</p> <p>Aqui \u00e9 que o PCA \u00e9 ajustado apenas no conjunto de treino, usando: x_train_pca = pca.fit_transform(x_train)</p> <p>Isso significa que o PCA aprende sua transforma\u00e7\u00e3o apenas com os dados que o modelo pode ver durante o treinamento \u2014 evitando vazamento de informa\u00e7\u00e3o do teste.</p> <p>Depois disso, o mesmo PCA transformado \u00e9 aplicado ao conjunto de teste, sem novo ajuste: x_test_pca = pca.transform(x_test)</p> <pre><code># PCA treinado APENAS no conjunto de treino\npca = PCA(n_components=2)\nx_train_pca = pca.fit_transform(x_train)\nx_test_pca = pca.transform(x_test)\n</code></pre>"},{"location":"svm/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"Kernel Acur\u00e1cia linear 0.9240 sigmoid 0.8889 poly 0.8480 rbf 0.9123"},{"location":"svm/main/#representacao","title":"Representa\u00e7\u00e3o :","text":"<ul> <li> <p>Foram avaliadas quatro variantes do SVM, cada uma utilizando um kernel diferente: linear, sigmoid, polynomial (poly) e rbf.</p> </li> <li> <p>Kernel Linear (0.9240) \u2014 Melhor desempenho A alta acur\u00e1cia indica que, ap\u00f3s o PCA, os dados tornam-se essencialmente separ\u00e1veis por uma fronteira linear. Isso sugere que a estrutura do problema \u00e9 relativamente simples no espa\u00e7o reduzido.</p> </li> <li> <p>Kernel RBF (0.9123) \u2014 Segundo melhor Mesmo sendo mais flex\u00edvel, o RBF n\u00e3o superou o kernel linear, mostrando que a complexidade extra n\u00e3o traz ganho real neste cen\u00e1rio.</p> </li> <li> <p>Kernel Sigmoid (0.8889) \u2014 Desempenho intermedi\u00e1rio O kernel sigmoid tende a ser menos est\u00e1vel e frequentemente oferece resultados inferiores em compara\u00e7\u00e3o a kernels mais robustos.</p> </li> <li> <p>Kernel Poly (0.8480) \u2014 Pior desempenho A fronteira polinomial acaba gerando uma complexidade que n\u00e3o reflete bem a estrutura dos dados, prejudicando a generaliza\u00e7\u00e3o.</p> </li> </ul>"},{"location":"svm/main/#relatorio-final","title":"Relat\u00f3rio Final","text":""},{"location":"svm/main/#os-experimentos-mostraram-que","title":"Os experimentos mostraram que:","text":"<p>O PCA cumpriu sua fun\u00e7\u00e3o ao comprimir a vari\u00e2ncia dos 30 atributos para duas dimens\u00f5es, permitindo uma separa\u00e7\u00e3o clara entre as classes.</p> <p>O SVM com kernel linear mostrou-se o mais adequado para o problema, fornecendo a melhor acur\u00e1cia e generaliza\u00e7\u00e3o.</p> <p>Kernels mais complexos, como RBF e Poly, n\u00e3o superaram o modelo linear, refor\u00e7ando que a separa\u00e7\u00e3o dos dados no espa\u00e7o PCA \u00e9 simples.</p>"},{"location":"svm/main/#possiveis-melhorias","title":"Poss\u00edveis Melhorias:","text":"<ul> <li> <p>Avalia\u00e7\u00e3o de SVM sem PCA, para comparar o impacto da redu\u00e7\u00e3o dimensional.</p> </li> <li> <p>Aplica\u00e7\u00e3o de normaliza\u00e7\u00e3o (StandardScaler) antes do PCA e do SVM.</p> </li> <li> <p>Ajuste de hiperpar\u00e2metros via GridSearchCV.</p> </li> <li> <p>Teste de outras m\u00e9tricas al\u00e9m da acur\u00e1cia: F1-score, recall, matriz de confus\u00e3o.</p> </li> <li> <p>Uso de m\u00e9todos mais robustos a ru\u00eddo, como Random Forest ou Gradient Boosting.</p> </li> </ul>"}]}