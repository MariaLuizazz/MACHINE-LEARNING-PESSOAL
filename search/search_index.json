{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega-machine-learning","title":"Template de Entrega - Machine Learning","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#template-pessoal","title":"Template Pessoal","text":"<ol> <li>Maria Oliveira</li> </ol> <p>Instru\u00e7\u00f5es</p> <p>HUMBERRTOOO se voc\u00ea chegou a esse template a minha \u00e1rvore de decis\u00e3o est\u00e1 na aba de ATIVIDADESS.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> \u00c1rvore de decis\u00e3o - Data 29/08/2025</li> <li> KNN - Data 16/09/2025</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"EXERCICIOAD/main/","title":"\u00c1rvore de decis\u00e3o","text":""},{"location":"EXERCICIOAD/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<p>Descri\u00e7\u00e3o da base de dados e c\u00f3digo de explora\u00e7\u00e3o</p> <p>O c\u00e2ncer de mama \u00e9 o tipo de c\u00e2ncer mais comum entre mulheres em todo o mundo, respons\u00e1vel por aproximadamente 25% de todos os casos e afetando milh\u00f5es de pessoas todos os anos. Ele se desenvolve quando c\u00e9lulas da mama come\u00e7am a crescer de forma descontrolada, formando tumores que podem ser identificados por exames de imagem (raios-X) ou detectados como n\u00f3dulos.</p> <p>O principal desafio no diagn\u00f3stico \u00e9 diferenciar corretamente os tumores malignos (cancerosos) dos benignos (n\u00e3o cancerosos). O objetivo deste projeto \u00e9 desenvolver um modelo de classifica\u00e7\u00e3o supervisionada capaz de prever, com base em atributos num\u00e9ricos das c\u00e9lulas, se um tumor \u00e9 maligno ou benigno.</p> <p>Sobre o Dataset</p> <p>Total de registros: 569 amostras</p> <p>Vari\u00e1vel alvo: diagnosis (M = maligno, B = benigno)</p> <p>N\u00famero de vari\u00e1veis preditoras: 30 atributos num\u00e9ricos relacionados ao tamanho, textura, formato e concavidade das c\u00e9lulas</p> CodeResultado <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\nprint(df.sample(n=10, random_state=42).to_markdown(index=False))\n</code></pre> id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 87930 B 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 859575 M 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 8670 M 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 907915 B 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 921385 B 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 927241 M 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 9012000 M 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 853201 M 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 8611161 B 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 911673 B 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698"},{"location":"EXERCICIOAD/main/#pre-processamento","title":"Pr\u00e9-Processamento","text":"<p>Explica\u00e7\u00e3o dos processos realizados no pr\u00e9-processamento</p> <p>Antes do treinamento do modelo, foi realizado um pr\u00e9-processamento para garantir a qualidade e consist\u00eancia dos dados:</p> <p>Remo\u00e7\u00e3o de colunas irrelevantes \u2013 A coluna id foi descartada, pois n\u00e3o contribui para o aprendizado do modelo.</p> <p>Tratamento de valores ausentes \u2013 Foram encontrados valores faltantes em algumas vari\u00e1veis (concavity_worst e concave points_worst). Esses valores foram preenchidos utilizando a mediana, por ser uma t\u00e9cnica robusta contra outliers.</p> <p>Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas \u2013 A vari\u00e1vel alvo diagnosis foi transformada em valores num\u00e9ricos por meio de Label Encoding (M = 1, B = 0), permitindo sua utiliza\u00e7\u00e3o pelo algoritmo de aprendizado.</p> CodeResultado <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n\n#pr\u00e9 processamento\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\nprint(df.to_markdown(index=False))\n</code></pre> diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 0 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 1 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 1 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 0 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 0 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 1 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 1 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 1 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 0 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 0 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698"},{"location":"EXERCICIOAD/main/#divisao-de-dados","title":"Divis\u00e3o de Dados","text":"<p>Separa\u00e7\u00e3o em treino e teste</p> <p>O dataset foi dividido em conjuntos de treino e teste para permitir a avalia\u00e7\u00e3o do modelo em dados n\u00e3o vistos durante o treinamento. Foram utilizadas duas propor\u00e7\u00f5es distintas:</p> <p>Etapa I: 80% treino, 20% teste</p> <p>Etapa II: 70% treino, 30% teste</p> <p>Essa varia\u00e7\u00e3o foi realizada para observar como a quantidade de dados de treino impacta o desempenho do modelo.</p> Code <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n\n#pr\u00e9 processamento\n\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#divis\u00e3o de treinamento e teste \nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\nprint(df.to_markdown(index=False))\n</code></pre>"},{"location":"EXERCICIOAD/main/#treinamento-do-modelo","title":"Treinamento do modelo","text":"<p>Etapas do treinamento</p> <p>Na etapa de treinamento, foi utilizado o algoritmo de \u00c1rvore de Decis\u00e3o, por ser um m\u00e9todo simples, interpret\u00e1vel e bastante utilizado em problemas de classifica\u00e7\u00e3o inicial.</p> <p>ETAPA I:</p> <p>Divis\u00e3o: 80% treino, 20% teste</p> <p>Resultado: 93% de acur\u00e1cia</p> <p>ETAPA II:</p> <p>Divis\u00e3o: 70% treino, 30% teste</p> <p>Resultado: 90% de acur\u00e1cia</p> <p>Os resultados mostram que pequenas varia\u00e7\u00f5es na divis\u00e3o dos dados afetam a acur\u00e1cia final, embora o desempenho geral do modelo tenha se mantido satisfat\u00f3rio.</p> Code <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#pr\u00e9 processamento\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#divis\u00e3o de treinamento e teste \nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(x_train, y_train)\n\nprint(df.sample(n=10, random_state=42).to_markdown(index=False))\n</code></pre>"},{"location":"EXERCICIOAD/main/#avaliacao-do-modelo-final","title":"Avalia\u00e7\u00e3o do Modelo Final","text":"<p>Ap\u00f3s os testes iniciais, foi feita a avalia\u00e7\u00e3o final do modelo. O foco desta etapa foi verificar o comportamento da \u00e1rvore de decis\u00e3o em termos de acur\u00e1cia e complexidade. A \u00e1rvore gerada inicialmente se apresentou pequena, sugerindo que o modelo poderia estar simplificando demais os padr\u00f5es dos dados (underfitting). Ap\u00f3s ajustes na propor\u00e7\u00e3o de dados de treino, a \u00e1rvore tornou-se mais consistente, refletindo melhor as rela\u00e7\u00f5es entre as vari\u00e1veis. O modelo alcan\u00e7ou 90% de acur\u00e1cia no conjunto de teste, isso significa que, a cada 100 diagn\u00f3sticos, 90 foram corretos.</p> <p>Embora existam modelos que possam alcan\u00e7ar valores um pouco maiores (como 95%+), a escolha dos 90% foi intencional:</p> <p>Por que 90% foi considerado adequado?</p> <ul> <li>Balanceamento entre desempenho e generaliza\u00e7\u00e3o</li> <li>Acima de 90%, o modelo come\u00e7ava a apresentar sinais de overfitting.</li> </ul> <p>Import\u00e2ncia cl\u00ednica</p> <ul> <li>No contexto de c\u00e2ncer de mama, evitar falsos negativos (n\u00e3o detectar um tumor maligno) \u00e9 prioridade.</li> </ul> <p>Conclus\u00e3o da Avalia\u00e7\u00e3o</p> <p>O modelo final com 90% de acur\u00e1cia foi escolhido por representar o melhor equil\u00edbrio entre desempenho, generaliza\u00e7\u00e3o e relev\u00e2ncia pr\u00e1tica para o contexto m\u00e9dico.</p> <p>Breast Cancer Dataset</p> decision treecode <p>Accuracy: 0.90  2025-10-02T22:30:02.765326 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#pr\u00e9 processamento\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nx = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n\n#divis\u00e3o de treinamento e teste \nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier(random_state=42)\nclassifier.fit(x_train, y_train)\n\n# Plotar \u00e1rvore\nplt.figure(figsize=(12,10))\n\n# Avalia\u00e7\u00e3o o modelo, medindo a acuracia\naccuracy = classifier.score(x_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\ntree.plot_tree(classifier)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"EXERCICIOAD/main/#relatorio-final","title":"Relat\u00f3rio Final","text":"<p>Resumo do Projeto</p> <p>Este projeto teve como objetivo aplicar t\u00e9cnicas de Machine Learning para criar um modelo capaz de prever se um tumor de mama \u00e9 benigno ou maligno, utilizando o dataset Breast Cancer (Diagnostic).</p> <ul> <li>As etapas seguidas foram:</li> </ul> <p>Explora\u00e7\u00e3o de dados - Pr\u00e9-processamento - Divis\u00e3o de dados \u2013 separa\u00e7\u00e3o em treino e teste - Treinamento do modelo - Avalia\u00e7\u00e3o do modelo \u2013 an\u00e1lise do desempenho final com base na acur\u00e1cia e na estrutura da \u00e1rvore.</p> <p>Resultados Obtidos</p> <ul> <li>Acur\u00e1cia variando entre 90% e 93%, dependendo da propor\u00e7\u00e3o de treino/teste utilizada.</li> </ul> <p>Conclus\u00e3o</p> <p>Mesmo com limita\u00e7\u00f5es, o projeto cumpriu seu objetivo: desenvolver um modelo de classifica\u00e7\u00e3o supervisionada e aplicar todo o fluxo de pr\u00e9-processamento, treino e avalia\u00e7\u00e3o, consolidando o  meu aprendizado sobre o processo de Machine Learning.</p>"},{"location":"KMEANS/main/","title":"KMEANS","text":""},{"location":"KMEANS/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<p>Descri\u00e7\u00e3o da base de dados e c\u00f3digo de explora\u00e7\u00e3o</p> <p>O c\u00e2ncer de mama \u00e9 o tipo de c\u00e2ncer mais comum entre mulheres em todo o mundo, respons\u00e1vel por aproximadamente 25% de todos os casos e afetando milh\u00f5es de pessoas todos os anos. Ele se desenvolve quando c\u00e9lulas da mama come\u00e7am a crescer de forma descontrolada, formando tumores que podem ser identificados por exames de imagem (raios-X) ou detectados como n\u00f3dulos.</p> <p>O principal desafio no diagn\u00f3stico \u00e9 diferenciar corretamente os tumores malignos (cancerosos) dos benignos (n\u00e3o cancerosos). O objetivo deste projeto \u00e9 desenvolver um modelo de classifica\u00e7\u00e3o supervisionada capaz de prever, com base em atributos num\u00e9ricos das c\u00e9lulas, se um tumor \u00e9 maligno ou benigno.</p> <p>Sobre o Dataset</p> <p>Total de registros: 569 amostras</p> <p>Vari\u00e1vel alvo: diagnosis (M = maligno, B = benigno)</p> <p>N\u00famero de vari\u00e1veis preditoras: 30 atributos num\u00e9ricos relacionados ao tamanho, textura, formato e concavidade das c\u00e9lulas</p> CodeResultado <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tabulate import tabulate  \n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\nprint(df.sample(n=10, random_state=42).to_markdown(index=False))\n</code></pre> id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 87930 B 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 859575 M 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 8670 M 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 907915 B 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 921385 B 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 927241 M 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 9012000 M 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 853201 M 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 8611161 B 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 911673 B 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698 <p>Cada ponto azul/roxo/amarelo no gr\u00e1fico \u00e9 um paciente representado nessas duas dimens\u00f5es condensadas.</p> <p>Esses componentes carregam a maior parte da variabilidade dos dados originais (30 features)</p> <p>Voc\u00ea aplicou PCA para reduzir a dimensionalidade dos dados.</p> <p>O primeiro componente principal explica \u224844,3% da vari\u00e2ncia total dos dados.</p> <p>O segundo componente principal explica \u224818,97% da vari\u00e2ncia.</p> <p>Isso significa que, juntos, os dois componentes capturam \u224863,2% da informa\u00e7\u00e3o original do dataset.</p>"},{"location":"KMEANS/main/#relatorio-do-modelo-k-means-com-pca","title":"Relat\u00f3rio do Modelo: K-Means com PCA","text":""},{"location":"KMEANS/main/#1-descricao-do-modelo","title":"1. Descri\u00e7\u00e3o do Modelo","text":"<p>O modelo aplicado combina duas t\u00e9cnicas:</p> <ol> <li>PCA (An\u00e1lise de Componentes Principais): usada para reduzir a dimensionalidade dos dados originais, mantendo a maior parte da variabilidade.  </li> <li>K-Means: algoritmo de clustering que agrupa os dados em 3 clusters distintos com base na proximidade aos centr\u00f3ides.</li> </ol> <p>O objetivo do modelo \u00e9 identificar agrupamentos naturais nos dados de c\u00e2ncer de mama, considerando as caracter\u00edsticas das c\u00e9lulas.</p>"},{"location":"KMEANS/main/#2-variancia-explicada-pelos-componentes-principais","title":"2. Vari\u00e2ncia Explicada pelos Componentes Principais","text":"Componente Principal Vari\u00e2ncia Explicada Vari\u00e2ncia Acumulada PC1 0,44272 0,44272 PC2 0,189712 0,632432 <ul> <li>PC1 explica aproximadamente 44,3% da vari\u00e2ncia dos dados.  </li> <li>PC2 explica aproximadamente 18,97%.  </li> <li>Vari\u00e2ncia total explicada pelos 2 componentes: 63,24%.  </li> </ul> <p>Interpreta\u00e7\u00e3o: Mais da metade da informa\u00e7\u00e3o original dos dados \u00e9 preservada nesses dois componentes, permitindo uma visualiza\u00e7\u00e3o e an\u00e1lise de clusters eficaz.</p>"},{"location":"KMEANS/main/#3-centroides-finais-dos-clusters","title":"3. Centr\u00f2ides Finais dos Clusters","text":"<p>Os centr\u00f3ides identificados pelo K-Means no espa\u00e7o reduzido (PCA) s\u00e3o:</p> <p>[[ 2.67596132 3.31195566] \u2192 Cluster 1 [-2.3259273 -0.20749033] \u2192 Cluster 2 [ 4.90974577 -1.89255356]] \u2192 Cluster 3</p> <ul> <li>Cada centr\u00f3ide representa o \u201cponto m\u00e9dio\u201d de cada cluster.  </li> <li>Cada ponto do dataset \u00e9 atribu\u00eddo ao cluster cujo centr\u00f3ide est\u00e1 mais pr\u00f3ximo.</li> </ul>"},{"location":"KMEANS/main/#4-inercia-wcss","title":"4. In\u00e9rcia (WCSS)","text":"<ul> <li>In\u00e9rcia final: 3871,15  </li> <li>Representa a soma das dist\u00e2ncias quadr\u00e1ticas dos pontos aos seus centr\u00f3ides.  </li> <li>Quanto menor a in\u00e9rcia, mais compactos s\u00e3o os clusters.</li> </ul> <p>Interpreta\u00e7\u00e3o pr\u00e1tica: A dispers\u00e3o dos clusters \u00e9 moderada. Para otimizar o n\u00famero de clusters, pode-se usar o m\u00e9todo do cotovelo.</p>"},{"location":"KMEANS/main/#5-grafico-dos-clusters","title":"5. Gr\u00e1fico dos Clusters","text":"ResultCode 2025-10-02T22:30:03.336958 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport pandas as pd\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n# Features\nX = df.drop(columns=['diagnosis', 'id'])\n\n\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n\nkmeans = KMeans(n_clusters=3, init='k-means++', max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Adicionar clusters ao dataframe\ndf['Cluster'] = labels\n\nplt.figure(figsize=(10, 8))\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', s=50)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n            c='red', marker='*', s=200, label='Centr\u00f3ides')\nplt.title('Clusters ap\u00f3s redu\u00e7\u00e3o de dimensionalidade (PCA)')\nplt.xlabel('Componente Principal 1')\nplt.ylabel('Componente Principal 2')\nplt.legend()\nplt.show()\n\n\n\n\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"KMEANS/main/#6-conclusao","title":"6. Conclus\u00e3o","text":"<ul> <li>O modelo reduziu os dados para 2 dimens\u00f5es mantendo 63% da vari\u00e2ncia, facilitando visualiza\u00e7\u00e3o.  </li> <li>Foram identificados 3 clusters distintos, cada um representado por um centr\u00f3ide.  </li> <li> <p>O WCSS sugere que os clusters s\u00e3o relativamente coesos.</p> </li> <li> <p>Explorar mais componentes do PCA para capturar mais variabilidade.  </p> </li> <li>Testar diferentes n\u00fameros de clusters (K) usando o m\u00e9todo do cotovelo.  </li> <li>Investigar quais caracter\u00edsticas impactam mais a separa\u00e7\u00e3o dos clusters.</li> </ul>"},{"location":"KNN/main/","title":"KNN","text":""},{"location":"KNN/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<p>Descri\u00e7\u00e3o da base de dados e c\u00f3digo de explora\u00e7\u00e3o</p> <p>O c\u00e2ncer de mama \u00e9 o tipo de c\u00e2ncer mais comum entre mulheres em todo o mundo, respons\u00e1vel por aproximadamente 25% de todos os casos e afetando milh\u00f5es de pessoas todos os anos. Ele se desenvolve quando c\u00e9lulas da mama come\u00e7am a crescer de forma descontrolada, formando tumores que podem ser identificados por exames de imagem (raios-X) ou detectados como n\u00f3dulos.</p> <p>O principal desafio no diagn\u00f3stico \u00e9 diferenciar corretamente os tumores malignos (cancerosos) dos benignos (n\u00e3o cancerosos). O objetivo deste projeto \u00e9 desenvolver um modelo de classifica\u00e7\u00e3o supervisionada capaz de prever, com base em atributos num\u00e9ricos das c\u00e9lulas, se um tumor \u00e9 maligno ou benigno, e estabelecer um diagn\u00f3stico confi\u00e1vel.</p> <p>Sobre o Dataset</p> <p>Total de registros: 569 amostras</p> <p>Vari\u00e1vel alvo: diagnosis (M = maligno, B = benigno)</p> <p>N\u00famero de vari\u00e1veis preditoras: 30 atributos num\u00e9ricos relacionados ao tamanho, textura, formato e concavidade das c\u00e9lulas.</p> Resultado id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 87930 B 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 859575 M 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 8670 M 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 907915 B 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 921385 B 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 927241 M 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 9012000 M 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 853201 M 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 8611161 B 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 911673 B 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698"},{"location":"KNN/main/#pre-processamento","title":"Pr\u00e9 processamento","text":"<p>Explica\u00e7\u00e3o dos processos realizados no pr\u00e9-processamento</p> <p>Antes do treinamento do modelo, foi realizado um pr\u00e9-processamento para garantir a qualidade e consist\u00eancia dos dados:</p> <p>Remo\u00e7\u00e3o de colunas irrelevantes \u2013 A coluna id foi descartada, pois n\u00e3o contribui para o aprendizado do modelo.</p> <p>Tratamento de valores ausentes \u2013 Foram encontrados valores faltantes em algumas vari\u00e1veis (concavity_worst e concave points_worst). Esses valores foram preenchidos utilizando a mediana.</p> <p>Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas \u2013 A vari\u00e1vel alvo diagnosis foi transformada em valores num\u00e9ricos por meio de Label Encoding (M = 1, B = 0), permitindo sua utiliza\u00e7\u00e3o pelo algoritmo de aprendizado.</p> <p>Todos os processos de pr\u00e9-processamento feitos no algoritmo de \u00e1rvore de decis\u00e3o foram feitos tamb\u00e9m no algoritmo de KNN.</p> CodeResultado <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n\n#pr\u00e9 processamento\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n#features escolhidas, todas menos diagnosis e id\nX = df.drop(columns=['diagnosis'])\ny = df['diagnosis']\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\nprint(df.sample(n=10, random_state=42).to_markdown(index=False))\n</code></pre> diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 0 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 1 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 1 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 0 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 0 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 1 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 1 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 1 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 0 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 0 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698"},{"location":"KNN/main/#divisao-dos-dados-treinamento-do-modelo-e-avaliacao-do-modelo","title":"Divis\u00e3o dos dados, Treinamento do Modelo e Avalia\u00e7\u00e3o do Modelo.","text":"<p>O dataset foi dividido em conjuntos de treino e teste com uma propor\u00e7\u00e3o de 80% treino e 20% teste.</p> <p>O questionamento principal foi: Quais features s\u00e3o mais relevantes para o diagn\u00f3stico de c\u00e2ncer de mama de acordo com o que foi fornecido no meu dataset?</p> <p>Ao analisar o dataset, foi bom lembrar que trata-se da previs\u00e3o de um diagn\u00f3stico, \u00e9 preciso entender a base e o que eu quero prever. Em uma pesquisa r\u00e1pida para entender melhor, conclu\u00ed que: para a escolha das minhas features eu deveria ficar atenta \u00e0s minhas vari\u00e1veis mais relevantes.</p> <p>Se o n\u00f3dulo \u00e9 redondo, pequeno e com bordas suaves \u2192 mais prov\u00e1vel benigno. Se o n\u00f3dulo \u00e9 grande, irregular, com bordas cheias de reentr\u00e2ncias \u2192 mais prov\u00e1vel maligno. N\u00f3dulos malignos costumam ser maiores, com contornos irregulares e n\u00e3o lisos, enquanto benignos tendem a ser mais arredondados e bem delimitados.</p> <p>Portanto, as vari\u00e1veis mais importantes do meu dataset para o diagn\u00f3stico seriam aquelas que especificam tamanho, formato e textura do n\u00f3dulo. No caso, as vari\u00e1veis escolhidas foram: texture_mean e radius_mean.</p> <p>TESTE 1 </p> <p>Ao analiser o primeiro gr\u00e1fico, o modelo paresentou sinais de overfitting, realizando uma valida\u00e7\u00e3o cruzada e matriz de confus\u00e3o foi  poss\u00edvel constatar que de acordo com o modelo sem balancemanto e com k = 3 que: </p> <p>102: Pacientes saud\u00e1veis corretamente diagnosticados</p> <p>5: Pacientes saud\u00e1veis erroneamente diagnosticados com c\u00e2ncer (Falso Positivo)</p> <p>14: Pacientes com c\u00e2ncer erroneamente diagnosticados como saud\u00e1veis (Falso Negativo - GRAVE)</p> <p>50: Pacientes com c\u00e2ncer corretamente diagnosticados</p> <p>Com esses erros o gr\u00e1fico resultou da seguinte forma: </p> ResultCode <p>Accuracy: 0.89  2025-10-02T22:30:05.294743 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/   Valida\u00e7\u00e3o Cruzada: 0.873 \u00b1 0.037 Matriz de Confus\u00e3o: [[102   5]  [ 14  50]] </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n\nplt.figure(figsize=(12,10))\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#Pr\u00e9process\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#escolha de features\nX = df[['radius_mean', 'texture_mean']]\ny = df['diagnosis']\n\n#Separa\u00e7\u00e3o de treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n#Treianamento do KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n\n\n#Teste e valida\u00e7\u00e3o\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n\n# Mapeia os r\u00f3tulos: 0 -&gt; Benigno, 1 -&gt; Maligno\nlabels_map = {0: \"Benigno\", 1: \"Maligno\"}\ny_labels = y.map(labels_map)\n\n\n#Prepara\u00e7\u00e3o para o gr\u00e1fico da fronteira de decis\u00e3o(malha de visualiza\u00e7\u00e3o)\nh = 0.02\nx_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\ny_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n\n#Prevendo classe em cada ponto\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n#gr\u00e1fico final\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlGn_r, alpha=0.3)\nsns.scatterplot(x=X.iloc[:, 0], y=X.iloc[:, 1], hue=y_labels, style=y_labels, palette={'Benigno': 'green', 'Maligno': 'red'}, s=100) #motivooooooo do errroo\nplt.xlabel(\"radius_mean\")\nplt.ylabel(\"texture_mean\")\nplt.title(\"KNN Decision Boundary (k=3) -  Diagn\u00f3stico de C\u00e2ncer\")\nplt.legend(title=\"Diagn\u00f3stico\")  \n\n\n\n#Exibi\u00e7\u00e3o do gr\u00e1fico\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n\n\n# 1. Valida\u00e7\u00e3o Cruzada\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(knn, X, y, cv=5)\nprint(f\"Valida\u00e7\u00e3o Cruzada: {scores.mean():.3f} \u00b1 {scores.std():.3f}\")\n\n\n# 3. Matriz de Confus\u00e3o\nfrom sklearn.metrics import confusion_matrix\nprint(\"Matriz de Confus\u00e3o:\")\nprint(confusion_matrix(y_test, predictions))\n</code></pre> <p>TESTE 2 </p> <p>No teste 2 ocorreu aplica\u00e7\u00e3o da t\u00e9cnica smote  apenas nos dados de treino para balanceamento, sem vazmento de informa\u00e7\u00f5es para o teste. Realizando uma valida\u00e7\u00e3o cruzada e matriz de confus\u00e3o foi  poss\u00edvel constatar que de acordo com o modelo co balancemento e com k = 11 que: </p> <p>O modelo balanceado com K=11 \u00e9 MAIS SEGURO que a vers\u00e3o anterior, reduzindo os perigosos falsos negativos em 28,6%.</p> <p>101: Pacientes saud\u00e1veis corretamente diagnosticados</p> <p>6: Pacientes saud\u00e1veis erroneamente diagnosticados com c\u00e2ncer (Falso Positivo)</p> <p>10: Pacientes com c\u00e2ncer erroneamente diagnosticados como saud\u00e1veis (Falso Negativo - GRAVE)</p> <p>54: Pacientes com c\u00e2ncer corretamente diagnosticados</p> <ul> <li>Conclus\u00e3o: a quantidade de falsos negativos cairam, e de positivos aumentou.</li> </ul> ResultCode <p>Accuracy: 0.91  2025-10-02T22:30:08.060901 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/   Valida\u00e7\u00e3o Cruzada: 0.884 \u00b1 0.036 Matriz de Confus\u00e3o: [[101   6]  [ 10  54]] </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE  \n\n\nplt.figure(figsize=(12,10))\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#Pr\u00e9process\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#escolha de features\n# Em vez de usar apenas 2 features\nX = df[['radius_mean', 'texture_mean']]\ny = df['diagnosis']\n\n#Separa\u00e7\u00e3o de treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\n\n\n#Treianamento do KNN\nknn = KNeighborsClassifier(n_neighbors=11)\nknn.fit(X_train_balanced, y_train_balanced) \n\n\n#Teste e valida\u00e7\u00e3o\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n\n# Mapeia os r\u00f3tulos: 0 -&gt; Benigno, 1 -&gt; Maligno\nlabels_map = {0: \"Benigno\", 1: \"Maligno\"}\ny_labels = y.map(labels_map)\n\n\n#Prepara\u00e7\u00e3o para o gr\u00e1fico da fronteira de decis\u00e3o(malha de visualiza\u00e7\u00e3o)\nh = 0.02\nx_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\ny_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n\n#Prevendo classe em cada ponto\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n#gr\u00e1fico final\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlGn_r, alpha=0.3)\nsns.scatterplot(x=X.iloc[:, 0], y=X.iloc[:, 1], hue=y_labels, style=y_labels, palette={'Benigno': 'green', 'Maligno': 'red'}, s=100) #motivooooooo do errroo\nplt.xlabel(\"radius_mean\")\nplt.ylabel(\"texture_mean\")\nplt.title(\"KNN Decision Boundary (k=11) - Diagn\u00f3stico de C\u00e2ncer (Com Balanceamento SMOTE)\")\nplt.legend(title=\"Diagn\u00f3stico\")  \n\n\n\n#Exibi\u00e7\u00e3o do gr\u00e1fico\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n\n\n\n# 1. Valida\u00e7\u00e3o Cruzada\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(knn, X, y, cv=5)\nprint(f\"Valida\u00e7\u00e3o Cruzada: {scores.mean():.3f} \u00b1 {scores.std():.3f}\")\n\n\n\n# 3. Matriz de Confus\u00e3o\nfrom sklearn.metrics import confusion_matrix\nprint(\"Matriz de Confus\u00e3o:\")\nprint(confusion_matrix(y_test, predictions))\n</code></pre>"},{"location":"KNN/main/#relatorio-final","title":"Relatorio final","text":"<ul> <li> <p>O modelo KNN com k=3 memoriza os dados de treino e usa dist\u00e2ncia para fazer previs\u00f5es. Para cada novo tumor, ele encontra os 3 tumores mais similares no conjunto de treino e decide pela maioria, a mesma coisa ocorre com k = 11.</p> </li> <li> <p>Sobre a Avalia\u00e7\u00e3o: Ap\u00f3s a etapa de treino e teste, o processo entregou uma acur\u00e1cia de 86% que nos mostra que o modelo acerta 86 em cada 100 previs\u00f5es. </p> </li> <li> <p>Sobre a Visualiza\u00e7\u00e3o: A fronteira de decis\u00e3o mostra como o modelo separa tumores benignos de malignos. \u00c1reas coloridas mostram onde o modelo prev\u00ea cada classe. Observando o modelo e a acur\u00e1cia o modelo apresenta sinais de overfitting.</p> </li> </ul> <p>Conclus\u00f5es - O balanceamento com SMOTE foi crucial para melhorar a detec\u00e7\u00e3o de casos malignos - k=11 mostrou-se superior a k=3 para este problema m\u00e9dico - A troca especificidade-sensibilidade foi clinicamente vantajosa - O modelo balanceado \u00e9 mais seguro para aplica\u00e7\u00e3o cl\u00ednica</p>"},{"location":"METRICAS/main/","title":"METRICAS","text":""},{"location":"METRICAS/main/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de Dados","text":"<p>Descri\u00e7\u00e3o da base de dados e c\u00f3digo de explora\u00e7\u00e3o</p> <p>O c\u00e2ncer de mama \u00e9 o tipo de c\u00e2ncer mais comum entre mulheres em todo o mundo, respons\u00e1vel por aproximadamente 25% de todos os casos e afetando milh\u00f5es de pessoas todos os anos. Ele se desenvolve quando c\u00e9lulas da mama come\u00e7am a crescer de forma descontrolada, formando tumores que podem ser identificados por exames de imagem (raios-X) ou detectados como n\u00f3dulos.</p> <p>O principal desafio no diagn\u00f3stico \u00e9 diferenciar corretamente os tumores malignos (cancerosos) dos benignos (n\u00e3o cancerosos). O objetivo deste projeto \u00e9 desenvolver um modelo de classifica\u00e7\u00e3o supervisionada capaz de prever, com base em atributos num\u00e9ricos das c\u00e9lulas, se um tumor \u00e9 maligno ou benigno, e estabelecer um diagn\u00f3stico confi\u00e1vel.</p> <p>Sobre o Dataset</p> <p>Total de registros: 569 amostras</p> <p>Vari\u00e1vel alvo: diagnosis (M = maligno, B = benigno)</p> <p>N\u00famero de vari\u00e1veis preditoras: 30 atributos num\u00e9ricos relacionados ao tamanho, textura, formato e concavidade das c\u00e9lulas.</p> Resultado id diagnosis radius_mean texture_mean perimeter_mean area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean radius_se texture_se perimeter_se area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst 87930 B 12.47 18.6 81.09 481.9 0.09965 0.1058 0.08005 0.03821 0.1925 0.06373 0.3961 1.044 2.497 30.29 0.006953 0.01911 0.02701 0.01037 0.01782 0.003586 14.97 24.64 96.05 677.9 0.1426 0.2378 0.2671 0.1015 0.3014 0.0875 859575 M 18.94 21.31 123.6 1130 0.09009 0.1029 0.108 0.07951 0.1582 0.05461 0.7888 0.7975 5.486 96.05 0.004444 0.01652 0.02269 0.0137 0.01386 0.001698 24.86 26.58 165.9 1866 0.1193 0.2336 0.2687 0.1789 0.2551 0.06589 8670 M 15.46 19.48 101.7 748.9 0.1092 0.1223 0.1466 0.08087 0.1931 0.05796 0.4743 0.7859 3.094 48.31 0.00624 0.01484 0.02813 0.01093 0.01397 0.002461 19.26 26 124.9 1156 0.1546 0.2394 0.3791 0.1514 0.2837 0.08019 907915 B 12.4 17.68 81.47 467.8 0.1054 0.1316 0.07741 0.02799 0.1811 0.07102 0.1767 1.46 2.204 15.43 0.01 0.03295 0.04861 0.01167 0.02187 0.006005 12.88 22.91 89.61 515.8 0.145 0.2629 0.2403 0.0737 0.2556 0.09359 921385 B 11.54 14.44 74.65 402.9 0.09984 0.112 0.06737 0.02594 0.1818 0.06782 0.2784 1.768 1.628 20.86 0.01215 0.04112 0.05553 0.01494 0.0184 0.005512 12.26 19.68 78.78 457.8 0.1345 0.2118 0.1797 0.06918 0.2329 0.08134 927241 M 20.6 29.33 140.1 1265 0.1178 0.277 0.3514 0.152 0.2397 0.07016 0.726 1.595 5.772 86.22 0.006522 0.06158 0.07117 0.01664 0.02324 0.006185 25.74 39.42 184.6 1821 0.165 0.8681 0.9387 0.265 0.4087 0.124 9012000 M 22.01 21.9 147.2 1482 0.1063 0.1954 0.2448 0.1501 0.1824 0.0614 1.008 0.6999 7.561 130.2 0.003978 0.02821 0.03576 0.01471 0.01518 0.003796 27.66 25.8 195 2227 0.1294 0.3885 0.4756 0.2432 0.2741 0.08574 853201 M 17.57 15.05 115 955.1 0.09847 0.1157 0.09875 0.07953 0.1739 0.06149 0.6003 0.8225 4.655 61.1 0.005627 0.03033 0.03407 0.01354 0.01925 0.003742 20.01 19.52 134.9 1227 0.1255 0.2812 0.2489 0.1456 0.2756 0.07919 8611161 B 13.34 15.86 86.49 520 0.1078 0.1535 0.1169 0.06987 0.1942 0.06902 0.286 1.016 1.535 12.96 0.006794 0.03575 0.0398 0.01383 0.02134 0.004603 15.53 23.19 96.66 614.9 0.1536 0.4791 0.4858 0.1708 0.3527 0.1016 911673 B 13.9 16.62 88.97 599.4 0.06828 0.05319 0.02224 0.01339 0.1813 0.05536 0.1555 0.5762 1.392 14.03 0.003308 0.01315 0.009904 0.004832 0.01316 0.002095 15.14 21.8 101.2 718.9 0.09384 0.2006 0.1384 0.06222 0.2679 0.07698 <ol> <li>Prepara\u00e7\u00e3o dos Dados</li> </ol> <p>Os dados foram pr\u00e9-processados para garantir melhor qualidade nas previs\u00f5es. As principais etapas inclu\u00edram:</p> <p>Normaliza\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas.</p> <p>Aplica\u00e7\u00e3o do SMOTE (Synthetic Minority Oversampling Technique) para balanceamento das classes.</p> <p>Utiliza\u00e7\u00e3o de PCA (Principal Component Analysis) para redu\u00e7\u00e3o de dimensionalidade, garantindo menor complexidade e melhor desempenho computacional.</p> <ol> <li>Treinamento dos Modelos</li> </ol> <p>KNN (K-Nearest Neighbors): Algoritmo supervisionado baseado na proximidade dos vizinhos mais pr\u00f3ximos.</p> <p>KMeans (K-Means Clustering): Algoritmo n\u00e3o supervisionado de agrupamento, adaptado para a tarefa de classifica\u00e7\u00e3o.</p>"},{"location":"METRICAS/main/#aplicacao-da-tecnicas","title":"Aplica\u00e7\u00e3o da T\u00e9cnicas","text":"<p>Este projeto tem como objetivo avaliar e comparar o desempenho de dois algoritmos de Machine Learning \u2013 KNN (K-Nearest Neighbors) e KMeans (K-Means Clustering) \u2013 aplicados a um problema de classifica\u00e7\u00e3o bin\u00e1ria. A an\u00e1lise foi conduzida com foco em m\u00e9tricas de desempenho e matrizes de confus\u00e3o, de forma a compreender vantagens e limita\u00e7\u00f5es de cada abordagem.</p> <p>Implementa\u00e7\u00e3o do KNN </p> ResultadoCode <p>Accuracy: 0.91  2025-10-02T22:30:10.900226 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE  \n\n\nplt.figure(figsize=(12,10))\n\n#carregamento da base\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n#Pr\u00e9process\n#remo\u00e7\u00e3o da coluna id pois \u00e9 irrelevante para o modelo\ndf = df.drop(columns=['id'])\n\n#convers\u00e3o de letra para n\u00famero\nlabel_encoder = LabelEncoder()  \ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n\n#imputa\u00e7\u00e3o com mediana de valores ausentes nas features concavity_worts e concavity points_worst\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n#escolha de features\n# Em vez de usar apenas 2 features\nX = df[['radius_mean', 'texture_mean']]\ny = df['diagnosis']\n\n#Separa\u00e7\u00e3o de treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\n\n\n#Treianamento do KNN\nknn = KNeighborsClassifier(n_neighbors=11)\nknn.fit(X_train_balanced, y_train_balanced) \n\n\n#Teste e valida\u00e7\u00e3o\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n\n# Mapeia os r\u00f3tulos: 0 -&gt; Benigno, 1 -&gt; Maligno\nlabels_map = {0: \"Benigno\", 1: \"Maligno\"}\ny_labels = y.map(labels_map)\n\n\n#Prepara\u00e7\u00e3o para o gr\u00e1fico da fronteira de decis\u00e3o(malha de visualiza\u00e7\u00e3o)\nh = 0.02\nx_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\ny_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n\n#Prevendo classe em cada ponto\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n#gr\u00e1fico final\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlGn_r, alpha=0.3)\nsns.scatterplot(x=X.iloc[:, 0], y=X.iloc[:, 1], hue=y_labels, style=y_labels, palette={'Benigno': 'green', 'Maligno': 'red'}, s=100) #motivooooooo do errroo\nplt.xlabel(\"radius_mean\")\nplt.ylabel(\"texture_mean\")\nplt.title(\"KNN Decision Boundary (k=11) - Diagn\u00f3stico de C\u00e2ncer (Com Balanceamento SMOTE)\")\nplt.legend(title=\"Diagn\u00f3stico\")  \n\n\n\n#Exibi\u00e7\u00e3o do gr\u00e1fico\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre> <p>Implementa\u00e7\u00e3o do KMEANS </p> ResultadoCode 2025-10-02T22:30:11.093871 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport pandas as pd\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n# Features\nX = df.drop(columns=['diagnosis', 'id'])\n\n\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n\nkmeans = KMeans(n_clusters=3, init='k-means++', max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X_pca)\n\n# Adicionar clusters ao dataframe\ndf['Cluster'] = labels\n\nplt.figure(figsize=(10, 8))\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', s=50)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n            c='red', marker='*', s=200, label='Centr\u00f3ides')\nplt.title('Clusters ap\u00f3s redu\u00e7\u00e3o de dimensionalidade (PCA)')\nplt.xlabel('Componente Principal 1')\nplt.ylabel('Componente Principal 2')\nplt.legend()\nplt.show()\n\n\n\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"METRICAS/main/#matrizes-de-confusao","title":"Matrizes de Confus\u00e3o","text":"Resultado"},{"location":"METRICAS/main/#exec-7--matriz-de-confusao-knn","title":"Matriz de Confus\u00e3o - KNN","text":"Previsto Benigno Previsto Maligno Real Benigno 99 8 Real Maligno 7 57"},{"location":"METRICAS/main/#exec-7--matriz-de-confusao-kmeans","title":"Matriz de Confus\u00e3o - KMeans","text":"Previsto Benigno Previsto Maligno Real Benigno 354 3 Real Maligno 53 159"},{"location":"METRICAS/main/#avaliacao-dos-modelos","title":"Avalia\u00e7\u00e3o dos Modelos","text":"ResultadoCode <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import mode\n\ndf = pd.read_csv('https://raw.githubusercontent.com/MariaLuizazz/MACHINE-LEARNING-PESSOAL/refs/heads/main/dados/breast-cancer.csv')\n\n# Pr\u00e9-processamento\ndf = df.drop(columns=['id'])\nlabel_encoder = LabelEncoder()\ndf['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n\n# Corrigir valores ausentes\ndf['concavity_mean'].fillna(df['concavity_mean'].median(), inplace=True)\ndf['concave points_mean'].fillna(df['concave points_mean'].median(), inplace=True)\n\n# Features selecionadas\nX = df[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n        'smoothness_mean', 'compactness_mean', 'concavity_mean']]\ny = df['diagnosis']\n\n#knn\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_pca, y, test_size=0.3, random_state=42, stratify=y\n)\n\n# Balanceamento com SMOTE\nsmote = SMOTE(random_state=42)\nX_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n\n# Treinamento do KNN\nknn = KNeighborsClassifier(n_neighbors=11)\nknn.fit(X_train_bal, y_train_bal)\n\n# Predi\u00e7\u00e3o\ny_pred_knn = knn.predict(X_test)\ncm_knn = confusion_matrix(y_test, y_pred_knn)\n\n# M\u00e9tricas KNN\nacc_knn = accuracy_score(y_test, y_pred_knn)\nprec_knn = precision_score(y_test, y_pred_knn)\nrec_knn = recall_score(y_test, y_pred_knn)\nf1_knn = f1_score(y_test, y_pred_knn)\n\n\n# Modelo 2: KMeans\nscaler_full = StandardScaler()\nX_scaled_full = scaler_full.fit_transform(X)\n\npca_full = PCA(n_components=2)\nX_pca_full = pca_full.fit_transform(X_scaled_full)\n\nkmeans = KMeans(n_clusters=2, init='k-means++', max_iter=100, random_state=42, n_init=10)\nclusters = kmeans.fit_predict(X_pca_full)\n\n# Mapear clusters para classes reais\nmapping = {}\nfor cluster in np.unique(clusters):\n    mask = clusters == cluster\n    mapping[cluster] = mode(y[mask], keepdims=True).mode[0]\n\ny_pred_kmeans = [mapping[c] for c in clusters]\ncm_kmeans = confusion_matrix(y, y_pred_kmeans)\n\n# M\u00e9tricas KMeans\nacc_kmeans = accuracy_score(y, y_pred_kmeans)\nprec_kmeans = precision_score(y, y_pred_kmeans)\nrec_kmeans = recall_score(y, y_pred_kmeans)\nf1_kmeans = f1_score(y, y_pred_kmeans)\n\n\n# Impress\u00e3o em Markdown\ndef matriz_markdown(cm, labels, titulo):\n    md = f\"### {titulo}\\n\\n\"\n    md += f\"|                 | Previsto {labels[0]} | Previsto {labels[1]} |\\n\"\n    md += f\"|-----------------|------------------|------------------|\\n\"\n    md += f\"| **Real {labels[0]}** | {cm[0,0]}              | {cm[0,1]}               |\\n\"\n    md += f\"| **Real {labels[1]}** | {cm[1,0]}              | {cm[1,1]}               |\\n\"\n    return md\n\nprint(matriz_markdown(cm_knn, [\"Benigno\", \"Maligno\"], \"Matriz de Confus\u00e3o - KNN\"))\nprint(f\"- Acur\u00e1cia: {acc_knn:.3f}\\n- Precis\u00e3o: {prec_knn:.3f}\\n- Recall: {rec_knn:.3f}\\n- F1-score: {f1_knn:.3f}\\n\")\n\nprint(matriz_markdown(cm_kmeans, [\"Benigno\", \"Maligno\"], \"Matriz de Confus\u00e3o - KMeans\"))\nprint(f\"- Acur\u00e1cia: {acc_kmeans:.3f}\\n- Precis\u00e3o: {prec_kmeans:.3f}\\n- Recall: {rec_kmeans:.3f}\\n- F1-score: {f1_kmeans:.3f}\\n\")\n\n\n# Compara\u00e7\u00e3o lado a lado em Markdown\ncomparacao = f\"\"\"\n### Compara\u00e7\u00e3o de M\u00e9tricas\n\n| Modelo   | Acur\u00e1cia | Precis\u00e3o | Recall | F1-score |\n|----------|----------|----------|--------|----------|\n| **KNN**  | {acc_knn:.3f} | {prec_knn:.3f} | {rec_knn:.3f} | {f1_knn:.3f} |\n| **KMeans**| {acc_kmeans:.3f} | {prec_kmeans:.3f} | {rec_kmeans:.3f} | {f1_kmeans:.3f} |\n\"\"\"\nprint(comparacao)\n</code></pre>"},{"location":"METRICAS/main/#exec-8--matriz-de-confusao-knn","title":"Matriz de Confus\u00e3o - KNN","text":"Previsto Benigno Previsto Maligno Real Benigno 99 8 Real Maligno 7 57 <ul> <li>Acur\u00e1cia: 0.912</li> <li>Precis\u00e3o: 0.877</li> <li>Recall: 0.891</li> <li>F1-score: 0.884</li> </ul>"},{"location":"METRICAS/main/#exec-8--matriz-de-confusao-kmeans","title":"Matriz de Confus\u00e3o - KMeans","text":"Previsto Benigno Previsto Maligno Real Benigno 354 3 Real Maligno 53 159 <ul> <li>Acur\u00e1cia: 0.902</li> <li>Precis\u00e3o: 0.981</li> <li>Recall: 0.750</li> <li>F1-score: 0.850</li> </ul>"},{"location":"METRICAS/main/#exec-8--comparacao-de-metricas","title":"Compara\u00e7\u00e3o de M\u00e9tricas","text":"Modelo Acur\u00e1cia Precis\u00e3o Recall F1-score KNN 0.912 0.877 0.891 0.884 KMeans 0.902 0.981 0.750 0.850"},{"location":"METRICAS/main/#comparacao-dos-resultados","title":"Compara\u00e7\u00e3o dos Resultados","text":"<p>A avalia\u00e7\u00e3o dos dois modelos (KNN e KMeans) permitiu observar diferen\u00e7as importantes em termos de desempenho, destacando pontos fortes e limita\u00e7\u00f5es de cada abordagem.</p> <p>O modelo KNN apresentou uma acur\u00e1cia de 91,2%, com m\u00e9tricas balanceadas entre precis\u00e3o (0,877), recall (0,891) e F1-score (0,884). Isso indica que o algoritmo teve um bom equil\u00edbrio entre identificar corretamente os casos benignos e malignos, sendo mais consistente no tratamento das duas classes. No entanto, a precis\u00e3o foi ligeiramente inferior, o que significa que, entre os casos previstos como malignos, houve uma propor\u00e7\u00e3o maior de falsos positivos em compara\u00e7\u00e3o ao KMeans.</p> <p>J\u00e1 o modelo KMeans, por se tratar de um algoritmo de aprendizado n\u00e3o supervisionado, surpreendeu ao alcan\u00e7ar uma acur\u00e1cia de 90,2%, pr\u00f3xima \u00e0 do KNN. Seu destaque foi a alta precis\u00e3o (0,981), ou seja, quase todas as amostras classificadas como malignas realmente pertenciam a essa classe. Por\u00e9m, essa alta precis\u00e3o veio acompanhada de uma queda no recall (0,750), mostrando que o KMeans deixou de identificar corretamente uma parcela consider\u00e1vel dos casos malignos, classificando-os como benignos. Isso \u00e9 cr\u00edtico em contextos sens\u00edveis, como o diagn\u00f3stico m\u00e9dico, em que falsos negativos podem trazer riscos significativos.</p> <ul> <li>De forma geral, pode-se afirmar que:</li> </ul> <p>O KNN \u00e9 mais equilibrado e confi\u00e1vel para cen\u00e1rios em que tanto falsos positivos quanto falsos negativos precisam ser controlados.</p> <p>O KMeans \u00e9 vantajoso em termos de precis\u00e3o, mas pode n\u00e3o ser o mais indicado em situa\u00e7\u00f5es em que a detec\u00e7\u00e3o completa dos casos positivos (alto recall) \u00e9 essencial.</p> <p>Portanto, a escolha entre os dois modelos depender\u00e1 diretamente do contexto de aplica\u00e7\u00e3o: se o objetivo for minimizar falsos negativos, o KNN se mostra mais adequado; se o objetivo for garantir maior seguran\u00e7a nas classifica\u00e7\u00f5es positivas, o KMeans pode ser preferido.</p>"},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"}]}